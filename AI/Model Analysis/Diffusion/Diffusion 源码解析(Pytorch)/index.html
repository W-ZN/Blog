
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="W Study Notes">
      
      
        <meta name="author" content="W">
      
      
      
        <link rel="prev" href="../../../Multimodal/Paper%20Reading/A%20Review%20on%20Methods%20and%20Applications%20in%20Multimodal%20Deep%20Learning/">
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.0.5">
    
    
      
        <title>Diffusion 源码解析(Pytorch) - W</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.558e4712.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.2505c338.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="green" data-md-color-accent="blue">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#运行方法" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="W" class="md-header__button md-logo" aria-label="W" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            W
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Diffusion 源码解析(Pytorch)
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="green" data-md-color-accent="blue"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
            </label>
          
        
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="green" data-md-color-accent="blue"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../../../.." class="md-tabs__link">
      Introduction
    </a>
  </li>

      
        
  
  
    
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../../NLP/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96/" class="md-tabs__link md-tabs__link--active">
        AI
      </a>
    </li>
  

  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="W" class="md-nav__button md-logo" aria-label="W" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    W
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        Introduction
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      
      
        <label class="md-nav__link" for="__nav_2" tabindex="0" aria-expanded="true">
          AI
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="AI" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          AI
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_2_1" type="checkbox" id="__nav_2_1" >
      
      
      
        <label class="md-nav__link" for="__nav_2_1" tabindex="0" aria-expanded="false">
          NLP
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="NLP" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_1">
          <span class="md-nav__icon md-icon"></span>
          NLP
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../NLP/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96/" class="md-nav__link">
        信息抽取
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../NLP/%E7%9F%A5%E8%AF%86%E6%8E%A8%E7%90%86/" class="md-nav__link">
        知识推理
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_2_1_3" type="checkbox" id="__nav_2_1_3" >
      
      
      
        <label class="md-nav__link" for="__nav_2_1_3" tabindex="0" aria-expanded="false">
          Paper Reading
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Paper Reading" data-md-level="3">
        <label class="md-nav__title" for="__nav_2_1_3">
          <span class="md-nav__icon md-icon"></span>
          Paper Reading
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../NLP/Paper%20Reading/Paper%20Reading/" class="md-nav__link">
        Summary
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_2_2" type="checkbox" id="__nav_2_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2_2" tabindex="0" aria-expanded="false">
          Multimodal
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Multimodal" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_2">
          <span class="md-nav__icon md-icon"></span>
          Multimodal
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_2_2_1" type="checkbox" id="__nav_2_2_1" >
      
      
      
        <label class="md-nav__link" for="__nav_2_2_1" tabindex="0" aria-expanded="false">
          Paper Reading
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Paper Reading" data-md-level="3">
        <label class="md-nav__title" for="__nav_2_2_1">
          <span class="md-nav__icon md-icon"></span>
          Paper Reading
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Multimodal/Paper%20Reading/A%20Review%20on%20Methods%20and%20Applications%20in%20Multimodal%20Deep%20Learning/" class="md-nav__link">
        A Review on Methods and Applications in Multimodal Deep Learning
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " data-md-toggle="__nav_2_3" type="checkbox" id="__nav_2_3" checked>
      
      
      
        <label class="md-nav__link" for="__nav_2_3" tabindex="0" aria-expanded="true">
          Model Analysis
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Model Analysis" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_3">
          <span class="md-nav__icon md-icon"></span>
          Model Analysis
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " data-md-toggle="__nav_2_3_1" type="checkbox" id="__nav_2_3_1" checked>
      
      
      
        <label class="md-nav__link" for="__nav_2_3_1" tabindex="0" aria-expanded="true">
          Diffusion
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Diffusion" data-md-level="3">
        <label class="md-nav__title" for="__nav_2_3_1">
          <span class="md-nav__icon md-icon"></span>
          Diffusion
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " data-md-toggle="__nav_2_3_1_1" type="checkbox" id="__nav_2_3_1_1" checked>
      
      
      
        <label class="md-nav__link" for="__nav_2_3_1_1" tabindex="0" aria-expanded="true">
          DDPM
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="DDPM" data-md-level="4">
        <label class="md-nav__title" for="__nav_2_3_1_1">
          <span class="md-nav__icon md-icon"></span>
          DDPM
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Diffusion 源码解析(Pytorch)
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Diffusion 源码解析(Pytorch)
      </a>
      
        

  

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#运行方法" class="md-nav__link">
    运行方法
  </a>
  
    <nav class="md-nav" aria-label="运行方法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#一维" class="md-nav__link">
    一维
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#多维" class="md-nav__link">
    多维
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1导入相关库" class="md-nav__link">
    1、导入相关库
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-dataset" class="md-nav__link">
    2、 Dataset
  </a>
  
    <nav class="md-nav" aria-label="2、 Dataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#一维_1" class="md-nav__link">
    一维
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#多维_1" class="md-nav__link">
    多维
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3trainer" class="md-nav__link">
    3、Trainer
  </a>
  
    <nav class="md-nav" aria-label="3、Trainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#part-1" class="md-nav__link">
    Part 1
  </a>
  
    <nav class="md-nav" aria-label="Part 1">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#一维_2" class="md-nav__link">
    一维
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#多维_2" class="md-nav__link">
    多维
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#part-2" class="md-nav__link">
    Part 2
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#part-3" class="md-nav__link">
    Part 3
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gaussiandiffusion" class="md-nav__link">
    GaussianDiffusion
  </a>
  
    <nav class="md-nav" aria-label="GaussianDiffusion">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#一维_3" class="md-nav__link">
    一维
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#多维_3" class="md-nav__link">
    多维
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model" class="md-nav__link">
    Model
  </a>
  
    <nav class="md-nav" aria-label="Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#construct" class="md-nav__link">
    Construct
  </a>
  
    <nav class="md-nav" aria-label="Construct">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#一维_4" class="md-nav__link">
    一维
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#多维_4" class="md-nav__link">
    多维
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#u-net" class="md-nav__link">
    U-Net
  </a>
  
    <nav class="md-nav" aria-label="U-Net">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#一维_5" class="md-nav__link">
    一维
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#多维_5" class="md-nav__link">
    多维
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#对比" class="md-nav__link">
    对比
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#运行方法" class="md-nav__link">
    运行方法
  </a>
  
    <nav class="md-nav" aria-label="运行方法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#一维" class="md-nav__link">
    一维
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#多维" class="md-nav__link">
    多维
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1导入相关库" class="md-nav__link">
    1、导入相关库
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-dataset" class="md-nav__link">
    2、 Dataset
  </a>
  
    <nav class="md-nav" aria-label="2、 Dataset">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#一维_1" class="md-nav__link">
    一维
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#多维_1" class="md-nav__link">
    多维
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3trainer" class="md-nav__link">
    3、Trainer
  </a>
  
    <nav class="md-nav" aria-label="3、Trainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#part-1" class="md-nav__link">
    Part 1
  </a>
  
    <nav class="md-nav" aria-label="Part 1">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#一维_2" class="md-nav__link">
    一维
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#多维_2" class="md-nav__link">
    多维
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#part-2" class="md-nav__link">
    Part 2
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#part-3" class="md-nav__link">
    Part 3
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gaussiandiffusion" class="md-nav__link">
    GaussianDiffusion
  </a>
  
    <nav class="md-nav" aria-label="GaussianDiffusion">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#一维_3" class="md-nav__link">
    一维
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#多维_3" class="md-nav__link">
    多维
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model" class="md-nav__link">
    Model
  </a>
  
    <nav class="md-nav" aria-label="Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#construct" class="md-nav__link">
    Construct
  </a>
  
    <nav class="md-nav" aria-label="Construct">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#一维_4" class="md-nav__link">
    一维
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#多维_4" class="md-nav__link">
    多维
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#u-net" class="md-nav__link">
    U-Net
  </a>
  
    <nav class="md-nav" aria-label="U-Net">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#一维_5" class="md-nav__link">
    一维
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#多维_5" class="md-nav__link">
    多维
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#对比" class="md-nav__link">
    对比
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  
  





  <h1>Diffusion 源码解析(Pytorch)</h1>

<p>该 Blog 是对 DDPM 对图片数据和一维数据代码的解读比较。</p>
<p>代码仓库：</p>
<blockquote>
<p><a href="https://github.com/lucidrains/denoising-diffusion-pytorch/tree/main">https://github.com/lucidrains/denoising-diffusion-pytorch/tree/main</a></p>
</blockquote>
<p>参考文献/文章：</p>
<ul>
<li><a href="https://arxiv.org/abs/2006.11239">https://arxiv.org/abs/2006.11239</a></li>
<li><a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">https://lilianweng.github.io/posts/2021-07-11-diffusion-models/</a></li>
<li><a href="https://huggingface.co/blog/annotated-diffusion">https://huggingface.co/blog/annotated-diffusion</a></li>
</ul>
<h2 id="运行方法">运行方法<a class="headerlink" href="#运行方法" title="Permanent link">&para;</a></h2>
<h3 id="一维">一维<a class="headerlink" href="#一维" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">denoising_diffusion_pytorch</span> <span class="kn">import</span> <span class="n">Unet1D</span><span class="p">,</span> <span class="n">GaussianDiffusion1D</span><span class="p">,</span> <span class="n">Trainer1D</span><span class="p">,</span> <span class="n">Dataset1D</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Unet1D</span><span class="p">(</span>
    <span class="n">dim</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
    <span class="n">dim_mults</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
    <span class="n">channels</span> <span class="o">=</span> <span class="mi">32</span>
<span class="p">)</span>

<span class="n">diffusion</span> <span class="o">=</span> <span class="n">GaussianDiffusion1D</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">seq_length</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
    <span class="n">timesteps</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="n">objective</span> <span class="o">=</span> <span class="s1">&#39;pred_v&#39;</span>
<span class="p">)</span>

<span class="n">training_seq</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span> <span class="c1"># features are normalized from 0 to 1</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">Dataset1D</span><span class="p">(</span><span class="n">training_seq</span><span class="p">)</span>  <span class="c1"># this is just an example, but you can formulate your own Dataset and pass it into the `Trainer1D` below</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">diffusion</span><span class="p">(</span><span class="n">training_seq</span><span class="p">)</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="c1"># Or using trainer</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer1D</span><span class="p">(</span>
    <span class="n">diffusion</span><span class="p">,</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">,</span>
    <span class="n">train_batch_size</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
    <span class="n">train_lr</span> <span class="o">=</span> <span class="mf">8e-5</span><span class="p">,</span>
    <span class="n">train_num_steps</span> <span class="o">=</span> <span class="mi">700000</span><span class="p">,</span>         <span class="c1"># total training steps</span>
    <span class="n">gradient_accumulate_every</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>    <span class="c1"># gradient accumulation steps</span>
    <span class="n">ema_decay</span> <span class="o">=</span> <span class="mf">0.995</span><span class="p">,</span>                <span class="c1"># exponential moving average decay</span>
    <span class="n">amp</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>                       <span class="c1"># turn on mixed precision</span>
<span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="c1"># after a lot of training</span>

<span class="n">sampled_seq</span> <span class="o">=</span> <span class="n">diffusion</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">sampled_seq</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># (4, 32, 128)</span>
</code></pre></div>
<hr />
<h3 id="多维">多维<a class="headerlink" href="#多维" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">denoising_diffusion_pytorch</span> <span class="kn">import</span> <span class="n">Unet</span><span class="p">,</span> <span class="n">GaussianDiffusion</span><span class="p">,</span> <span class="n">Trainer</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Unet</span><span class="p">(</span>
    <span class="n">dim</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
    <span class="n">dim_mults</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
    <span class="n">flash_attn</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span>

<span class="n">diffusion</span> <span class="o">=</span> <span class="n">GaussianDiffusion</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">image_size</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
    <span class="n">timesteps</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>           <span class="c1"># number of steps</span>
    <span class="n">sampling_timesteps</span> <span class="o">=</span> <span class="mi">250</span>    <span class="c1"># number of sampling timesteps (using ddim for faster inference [see citation for ddim paper])</span>
<span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">diffusion</span><span class="p">,</span>
    <span class="s1">&#39;path/to/your/images&#39;</span><span class="p">,</span>
    <span class="n">train_batch_size</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
    <span class="n">train_lr</span> <span class="o">=</span> <span class="mf">8e-5</span><span class="p">,</span>
    <span class="n">train_num_steps</span> <span class="o">=</span> <span class="mi">700000</span><span class="p">,</span>         <span class="c1"># total training steps</span>
    <span class="n">gradient_accumulate_every</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>    <span class="c1"># gradient accumulation steps</span>
    <span class="n">ema_decay</span> <span class="o">=</span> <span class="mf">0.995</span><span class="p">,</span>                <span class="c1"># exponential moving average decay</span>
    <span class="n">amp</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>                       <span class="c1"># turn on mixed precision</span>
    <span class="n">calculate_fid</span> <span class="o">=</span> <span class="kc">True</span>              <span class="c1"># whether to calculate fid during training</span>
<span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div>
<h2 id="1导入相关库">1、导入相关库<a class="headerlink" href="#1导入相关库" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">math</span>  
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>  
<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">random</span> 
<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">from</span> <span class="nn">ema_pytorch</span> <span class="kn">import</span> <span class="n">EMA</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>  
<span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>  
<span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="kn">import</span> <span class="n">cpu_count</span>  

<span class="kn">import</span> <span class="nn">torch</span>  
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">einsum</span><span class="p">,</span> <span class="n">Tensor</span>  
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>  
<span class="kn">from</span> <span class="nn">torch.cuda.amp</span> <span class="kn">import</span> <span class="n">autocast</span>  
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>  
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>  

<span class="kn">from</span> <span class="nn">einops</span> <span class="kn">import</span> <span class="n">rearrange</span><span class="p">,</span> <span class="n">reduce</span>  
<span class="kn">from</span> <span class="nn">einops.layers.torch</span> <span class="kn">import</span> <span class="n">Rearrange</span>  
</code></pre></div>
<p>导入库的功能如下所示：</p>
<ul>
<li><code>math</code>: 用于数学运算。</li>
<li><code>pathlib.Path</code>: 用于处理文件和目录路径的对象。</li>
<li><code>random.random</code>: 用于生成0到1之间的随机数。</li>
<li>
<p><code>tqdm</code>: 用于在循环中显示进度条。</p>
</li>
<li>
<p><code>ema_pytorch</code>: 用于指数移动平均（EMA）的PyTorch扩展。</p>
</li>
<li><code>functools.partial</code>: 用于创建偏函数。</li>
<li><code>accelerate</code>: 加速训练，用于自动混合精度和分布式训练。</li>
<li><code>collections.namedtuple</code>: 用于创建命名元组。</li>
<li>
<p><code>multiprocessing.cpu_count</code>: 用于获取计算机的CPU核心数。</p>
</li>
<li>
<p><code>torch</code>: PyTorch的根模块。</p>
</li>
<li><code>torch.nn</code>: 神经网络模块，包含了各种神经网络层和函数。</li>
<li><code>torch.cuda.amp.autocast</code>: 自动混合精度训练模块。</li>
<li><code>torch.optim.Adam</code>: Adam优化器。</li>
<li><code>torch.utils.data.Dataset</code>: 数据集类，用于自定义数据集。</li>
<li>
<p><code>torch.utils.data.DataLoader</code>: 数据加载器，用于批量加载数据。</p>
</li>
<li>
<p><code>einops</code>:提供了简洁的方式对PyTorch张量进行重组和操作。</p>
<ul>
<li><code>rearrange</code> 函数用于重新排列张量的维度；</li>
<li><code>reduce</code> 函数用于沿着指定的维度进行缩减操作（如求和、求平均等）；</li>
<li><code>Rearrange</code> 类是 <code>einops</code> 提供的一个PyTorch层，用于在PyTorch模型中重新排列张量的维度。</li>
</ul>
</li>
</ul>
<hr />
<h2 id="2-dataset">2、 Dataset<a class="headerlink" href="#2-dataset" title="Permanent link">&para;</a></h2>
<h3 id="一维_1">一维<a class="headerlink" href="#一维_1" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">Dataset1D</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>  
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">):</span>  
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>  
        <span class="bp">self</span><span class="o">.</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>  

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>  
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span>  

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>  
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</code></pre></div>
<p>该代码定义了一个一维的数据集类，用于处理一维数据。具体来说：</p>
<ul>
<li>
<p><code>__init__</code>：这是类的初始化函数，它接收一个Tensor作为参数，并将其克隆保存在self.tensor中。这样做的目的是为了避免在原始数据上进行修改。</p>
</li>
<li>
<p><code>__len__</code>：这个方法返回数据集的大小，也就是一维数据的长度。在PyTorch的数据加载器（DataLoader）中，这个方法被用来确定每个epoch的迭代次数。</p>
</li>
<li>
<p><code>__getitem__</code>：这个方法接收一个索引，返回对应索引的数据。在PyTorch的数据加载器（DataLoader）中，这个方法被用来按需加载数据，这样可以节省内存，提高数据加载的效率。</p>
</li>
</ul>
<h3 id="多维_1">多维<a class="headerlink" href="#多维_1" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">Dataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">folder</span><span class="p">,</span>
        <span class="n">image_size</span><span class="p">,</span>
        <span class="n">exts</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;jpg&#39;</span><span class="p">,</span> <span class="s1">&#39;jpeg&#39;</span><span class="p">,</span> <span class="s1">&#39;png&#39;</span><span class="p">,</span> <span class="s1">&#39;tiff&#39;</span><span class="p">],</span>
        <span class="n">augment_horizontal_flip</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">convert_image_to</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">folder</span> <span class="o">=</span> <span class="n">folder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span> <span class="o">=</span> <span class="n">image_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">ext</span> <span class="ow">in</span> <span class="n">exts</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">Path</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">folder</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;**/*.</span><span class="si">{</span><span class="n">ext</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)]</span>

        <span class="n">maybe_convert_fn</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">convert_image_to_fn</span><span class="p">,</span> <span class="n">convert_image_to</span><span class="p">)</span> <span class="k">if</span> <span class="n">exists</span><span class="p">(</span><span class="n">convert_image_to</span><span class="p">)</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
            <span class="n">T</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="n">maybe_convert_fn</span><span class="p">),</span>
            <span class="n">T</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">image_size</span><span class="p">),</span>
            <span class="n">T</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">()</span> <span class="k">if</span> <span class="n">augment_horizontal_flip</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">(),</span>
            <span class="n">T</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="n">image_size</span><span class="p">),</span>
            <span class="n">T</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
        <span class="p">])</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">paths</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">paths</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</code></pre></div>
<p>相对于处理一维数据的 Dataset，该数据集用于处理图片。具体来说，这个类的输入是一个图片文件夹的路径，而不是一个Tensor。它会搜索这个文件夹中的所有图片文件，并将它们的路径保存在self.paths中；同时，该类在 <code>__init__</code> 中定义了一个数据预处理流程，这个流程包括图片格式转换、图片大小调整、随机水平翻转、中心裁剪和转换为Tensor。这个预处理流程会在<code>__getitem__</code>方法中被应用到每一张图片上。</p>
<p><code>__getitem__</code>方法最后返回的Tensor的形状应该是<code>(C, H, W)</code>，其中：</p>
<ul>
<li><code>C</code> 是通道数，对于彩色图片，通道数通常是3（RGB）；对于灰度图片，通道数是1。</li>
<li><code>H</code> 是图片的高度，这个值由<code>image_size</code>参数决定，这个参数在初始化数据集类时被传入。</li>
<li><code>W</code> 是图片的宽度，这个值也由<code>image_size</code>参数决定。</li>
</ul>
<h2 id="3trainer">3、Trainer<a class="headerlink" href="#3trainer" title="Permanent link">&para;</a></h2>
<h3 id="part-1">Part 1<a class="headerlink" href="#part-1" title="Permanent link">&para;</a></h3>
<h4 id="一维_2">一维<a class="headerlink" href="#一维_2" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">Trainer1D</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">diffusion_model</span><span class="p">:</span> <span class="n">GaussianDiffusion1D</span><span class="p">,</span>
        <span class="n">dataset</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">train_batch_size</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
        <span class="n">gradient_accumulate_every</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">train_lr</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">train_num_steps</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">,</span>
        <span class="n">ema_update_every</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">ema_decay</span> <span class="o">=</span> <span class="mf">0.995</span><span class="p">,</span>
        <span class="n">adam_betas</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">),</span>
        <span class="n">save_and_sample_every</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">25</span><span class="p">,</span>
        <span class="n">results_folder</span> <span class="o">=</span> <span class="s1">&#39;./results&#39;</span><span class="p">,</span>
        <span class="n">amp</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">mixed_precision_type</span> <span class="o">=</span> <span class="s1">&#39;fp16&#39;</span><span class="p">,</span>
        <span class="n">split_batches</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># accelerator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">(</span>
            <span class="n">split_batches</span> <span class="o">=</span> <span class="n">split_batches</span><span class="p">,</span>
            <span class="n">mixed_precision</span> <span class="o">=</span> <span class="n">mixed_precision_type</span> <span class="k">if</span> <span class="n">amp</span> <span class="k">else</span> <span class="s1">&#39;no&#39;</span>
        <span class="p">)</span>

        <span class="c1"># model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">diffusion_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">channels</span> <span class="o">=</span> <span class="n">diffusion_model</span><span class="o">.</span><span class="n">channels</span>

        <span class="c1"># sampling and training hyperparameters</span>
        <span class="k">assert</span> <span class="n">has_int_squareroot</span><span class="p">(</span><span class="n">num_samples</span><span class="p">),</span> <span class="s1">&#39;number of samples must have an integer square root&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">=</span> <span class="n">num_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_and_sample_every</span> <span class="o">=</span> <span class="n">save_and_sample_every</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">train_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_accumulate_every</span> <span class="o">=</span> <span class="n">gradient_accumulate_every</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_num_steps</span> <span class="o">=</span> <span class="n">train_num_steps</span>

        <span class="c1"># dataset and dataloader</span>
        <span class="n">dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">train_batch_size</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">pin_memory</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span> <span class="o">=</span> <span class="n">cpu_count</span><span class="p">())</span>
        <span class="n">dl</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">dl</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dl</span> <span class="o">=</span> <span class="n">cycle</span><span class="p">(</span><span class="n">dl</span><span class="p">)</span>

        <span class="c1"># optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">opt</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">diffusion_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">train_lr</span><span class="p">,</span> <span class="n">betas</span> <span class="o">=</span> <span class="n">adam_betas</span><span class="p">)</span>

        <span class="c1"># for logging results in a folder periodically</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ema</span> <span class="o">=</span> <span class="n">EMA</span><span class="p">(</span><span class="n">diffusion_model</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="n">ema_decay</span><span class="p">,</span> <span class="n">update_every</span> <span class="o">=</span> <span class="n">ema_update_every</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">results_folder</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">results_folder</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">results_folder</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

        <span class="c1"># step counter state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># prepare model, dataloader, optimizer with accelerator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="p">)</span>
</code></pre></div>
<p>这个初始化函数接受了很多参数，下面是每个参数的含义：</p>
<p><code>diffusion_model</code>: GaussianDiffusion1D模型对象，它是训练过程中需要优化的模型。</p>
<p><code>dataset</code>: 数据集对象，它提供了训练模型所需的数据。</p>
<p><code>train_batch_size</code>: 整数，表示每个训练批次的大小。</p>
<p><code>gradient_accumulate_every</code>: 整数，表示每隔多少步进行一次梯度累积。</p>
<p><code>train_lr</code>: 浮点数，表示训练的学习率。</p>
<p><code>train_num_steps</code>: 整数，表示训练的总步数。</p>
<p><code>ema_update_every</code>: 整数，表示每隔多少步更新一次指数移动平均（EMA）。</p>
<p><code>ema_decay</code>: 浮点数，表示EMA的衰减率。</p>
<p><code>adam_betas</code>: 元组，表示Adam优化器的beta参数。</p>
<p><code>save_and_sample_every</code>: 整数，表示每隔多少步保存一次模型并生成样本。</p>
<p><code>num_samples</code>: 整数，表示每次生成样本的数量。</p>
<p><code>results_folder</code>: 字符串，表示保存结果的文件夹路径。</p>
<p><code>amp</code>: 布尔值，表示是否使用自动混合精度（AMP）训练。</p>
<p><code>mixed_precision_type</code>: 字符串，表示混合精度的类型，可能的值是'fp16'或'fp32'。</p>
<p><code>split_batches</code>: 布尔值，表示是否将批次分割到多个设备上。</p>
<p>在初始化函数中，首先初始化了一个<code>Accelerator</code>对象，这个对象用于管理模型的设备分配和混合精度训练。然后，初始化了模型、训练参数、数据加载器和优化器。如果当前进程是主进程，还会初始化一个EMA对象，用于跟踪模型的移动平均。最后，准备了模型、数据加载器和优化器，以适应<code>Accelerator</code>的设置。</p>
<h4 id="多维_2">多维<a class="headerlink" href="#多维_2" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">Trainer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">diffusion_model</span><span class="p">,</span>
        <span class="n">folder</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">train_batch_size</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
        <span class="n">gradient_accumulate_every</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">augment_horizontal_flip</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">train_lr</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">train_num_steps</span> <span class="o">=</span> <span class="mi">100000</span><span class="p">,</span>
        <span class="n">ema_update_every</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">ema_decay</span> <span class="o">=</span> <span class="mf">0.995</span><span class="p">,</span>
        <span class="n">adam_betas</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">),</span>
        <span class="n">save_and_sample_every</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">25</span><span class="p">,</span>
        <span class="n">results_folder</span> <span class="o">=</span> <span class="s1">&#39;./results&#39;</span><span class="p">,</span>
        <span class="n">amp</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">mixed_precision_type</span> <span class="o">=</span> <span class="s1">&#39;fp16&#39;</span><span class="p">,</span>
        <span class="n">split_batches</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">convert_image_to</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">calculate_fid</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">inception_block_idx</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span>
        <span class="n">max_grad_norm</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">,</span>
        <span class="n">num_fid_samples</span> <span class="o">=</span> <span class="mi">50000</span><span class="p">,</span>
        <span class="n">save_best_and_latest_only</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># accelerator</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">(</span>
            <span class="n">split_batches</span> <span class="o">=</span> <span class="n">split_batches</span><span class="p">,</span>
            <span class="n">mixed_precision</span> <span class="o">=</span> <span class="n">mixed_precision_type</span> <span class="k">if</span> <span class="n">amp</span> <span class="k">else</span> <span class="s1">&#39;no&#39;</span>
        <span class="p">)</span>

        <span class="c1"># model</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">diffusion_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">channels</span> <span class="o">=</span> <span class="n">diffusion_model</span><span class="o">.</span><span class="n">channels</span>

        <span class="c1"># sampling and training hyperparameters</span>

        <span class="k">assert</span> <span class="n">has_int_squareroot</span><span class="p">(</span><span class="n">num_samples</span><span class="p">),</span> <span class="s1">&#39;number of samples must have an integer square root&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">=</span> <span class="n">num_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_and_sample_every</span> <span class="o">=</span> <span class="n">save_and_sample_every</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">train_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_accumulate_every</span> <span class="o">=</span> <span class="n">gradient_accumulate_every</span>
        <span class="k">assert</span> <span class="p">(</span><span class="n">train_batch_size</span> <span class="o">*</span> <span class="n">gradient_accumulate_every</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">16</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;your effective batch size (train_batch_size x gradient_accumulate_every) should be at least 16 or above&#39;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_num_steps</span> <span class="o">=</span> <span class="n">train_num_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span> <span class="o">=</span> <span class="n">diffusion_model</span><span class="o">.</span><span class="n">image_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_grad_norm</span> <span class="o">=</span> <span class="n">max_grad_norm</span>

        <span class="c1"># dataset and dataloader</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span><span class="p">,</span> <span class="n">augment_horizontal_flip</span> <span class="o">=</span> <span class="n">augment_horizontal_flip</span><span class="p">,</span> <span class="n">convert_image_to</span> <span class="o">=</span> <span class="n">convert_image_to</span><span class="p">)</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ds</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">100</span><span class="p">,</span> <span class="s1">&#39;you should have at least 100 images in your folder. at least 10k images recommended&#39;</span>

        <span class="n">dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ds</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">train_batch_size</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">pin_memory</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span> <span class="o">=</span> <span class="n">cpu_count</span><span class="p">())</span>

        <span class="n">dl</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">dl</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dl</span> <span class="o">=</span> <span class="n">cycle</span><span class="p">(</span><span class="n">dl</span><span class="p">)</span>

        <span class="c1"># optimizer</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">opt</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">diffusion_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">train_lr</span><span class="p">,</span> <span class="n">betas</span> <span class="o">=</span> <span class="n">adam_betas</span><span class="p">)</span>

        <span class="c1"># for logging results in a folder periodically</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ema</span> <span class="o">=</span> <span class="n">EMA</span><span class="p">(</span><span class="n">diffusion_model</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="n">ema_decay</span><span class="p">,</span> <span class="n">update_every</span> <span class="o">=</span> <span class="n">ema_update_every</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">results_folder</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">results_folder</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">results_folder</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

        <span class="c1"># step counter state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># prepare model, dataloader, optimizer with accelerator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="p">)</span>

        <span class="c1"># FID-score computation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">calculate_fid</span> <span class="o">=</span> <span class="n">calculate_fid</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_fid</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">is_ddim_sampling</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span>
                    <span class="s2">&quot;WARNING: Robust FID computation requires a lot of generated samples and can therefore be very time consuming.&quot;</span>\
                    <span class="s2">&quot;Consider using DDIM sampling to save time.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fid_scorer</span> <span class="o">=</span> <span class="n">FIDEvaluation</span><span class="p">(</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">dl</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dl</span><span class="p">,</span>
                <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="o">.</span><span class="n">ema_model</span><span class="p">,</span>
                <span class="n">channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">channels</span><span class="p">,</span>
                <span class="n">accelerator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="p">,</span>
                <span class="n">stats_dir</span><span class="o">=</span><span class="n">results_folder</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">num_fid_samples</span><span class="o">=</span><span class="n">num_fid_samples</span><span class="p">,</span>
                <span class="n">inception_block_idx</span><span class="o">=</span><span class="n">inception_block_idx</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">save_best_and_latest_only</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">calculate_fid</span><span class="p">,</span> <span class="s2">&quot;`calculate_fid` must be True to provide a means for model evaluation for `save_best_and_latest_only`.&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_fid</span> <span class="o">=</span> <span class="mf">1e10</span> <span class="c1"># infinite</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">save_best_and_latest_only</span> <span class="o">=</span> <span class="n">save_best_and_latest_only</span>
</code></pre></div>
<p>与上一个<code>__init__</code>函数相比，这个函数多了一些参数，主要是关于数据增强、图像格式转换和FID评分的参数。这些参数使得这个训练器更适合处理图像数据。不同/增加的参数如下：</p>
<p><code>folder</code>: 字符串，表示数据集的文件夹路径。</p>
<p><code>augment_horizontal_flip</code>: 布尔值，表示是否对图像进行水平翻转的数据增强。</p>
<p><code>convert_image_to</code>: 字符串，表示将图像转换为何种格式，可能的值是'RGB'或'YCbCr'。</p>
<p><code>calculate_fid</code>: 布尔值，表示是否计算Frechet Inception Distance（FID）评分。</p>
<p><code>inception_block_idx</code>: 整数，表示用于计算FID评分的Inception模型的哪个块的输出。</p>
<p><code>max_grad_norm</code>: 浮点数，表示梯度裁剪的阈值。</p>
<p><code>num_fid_samples</code>: 整数，表示用于计算FID评分的样本数量。</p>
<p><code>save_best_and_latest_only</code>: 布尔值，表示是否只保存最好和最新的模型。</p>
<hr />
<h3 id="part-2">Part 2<a class="headerlink" href="#part-2" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">milestone</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">is_local_main_process</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;step&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">,</span>
            <span class="s1">&#39;model&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">get_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">),</span>
            <span class="s1">&#39;opt&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;ema&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;scaler&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span> <span class="k">if</span> <span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">scaler</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s1">&#39;version&#39;</span><span class="p">:</span> <span class="n">__version__</span>
        <span class="p">}</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">results_folder</span> <span class="o">/</span> <span class="sa">f</span><span class="s1">&#39;model-</span><span class="si">{</span><span class="n">milestone</span><span class="si">}</span><span class="s1">.pt&#39;</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">milestone</span><span class="p">):</span>
        <span class="n">accelerator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">results_folder</span> <span class="o">/</span> <span class="sa">f</span><span class="s1">&#39;model-</span><span class="si">{</span><span class="n">milestone</span><span class="si">}</span><span class="s1">.pt&#39;</span><span class="p">),</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">unwrap_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;step&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;opt&#39;</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;ema&quot;</span><span class="p">])</span>

        <span class="k">if</span> <span class="s1">&#39;version&#39;</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;loading from version </span><span class="si">{</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;version&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">scaler</span><span class="p">)</span> <span class="ow">and</span> <span class="n">exists</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;scaler&#39;</span><span class="p">]):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;scaler&#39;</span><span class="p">])</span>
</code></pre></div>
<p><code>device</code>：返回训练器正在使用的设备，CPU或者GPU。</p>
<p><code>save</code>：保存训练器的状态，包括模型的参数、优化器的状态、训练步数等。函数在每个训练周期结束时被调用，用于保存训练的进度，以便在需要时恢复训练。</p>
<p><code>load</code>：加载保存的训练器状态，包括模型的参数、优化器的状态、训练步数等。函数在训练开始时被调用，用于从保存的状态恢复训练。</p>
<p>（一维与多维基本一致）</p>
<hr />
<h3 id="part-3">Part 3<a class="headerlink" href="#part-3" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">accelerator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>

        <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">initial</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_num_steps</span><span class="p">,</span> <span class="n">disable</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>

            <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_num_steps</span><span class="p">:</span>

                <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.</span>

                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gradient_accumulate_every</span><span class="p">):</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dl</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">autocast</span><span class="p">():</span>
                        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient_accumulate_every</span>
                        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

                <span class="n">accelerator</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="mf">1.0</span><span class="p">)</span>
                <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

                <span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

                    <span class="c1"># 判断是否达到了保存和采样的步数。如果达到了，就生成样本并保存模型</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_and_sample_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="o">.</span><span class="n">ema_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

                        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                            <span class="n">milestone</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_and_sample_every</span>
                            <span class="n">batches</span> <span class="o">=</span> <span class="n">num_to_groups</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
                            <span class="n">all_samples_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="o">.</span><span class="n">ema_model</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">n</span><span class="p">),</span> <span class="n">batches</span><span class="p">))</span>

                        <span class="n">all_samples</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_samples_list</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

                        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">all_samples</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">results_folder</span> <span class="o">/</span> <span class="sa">f</span><span class="s1">&#39;sample-</span><span class="si">{</span><span class="n">milestone</span><span class="si">}</span><span class="s1">.png&#39;</span><span class="p">))</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">milestone</span><span class="p">)</span>

                <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="s1">&#39;training complete&#39;</span><span class="p">)</span>
</code></pre></div>
<p><code>train</code>：训练器的主要函数，实现了模型的训练过程。函数在每个训练周期中被调用，用于执行模型的前向阶段和后向阶段，以及参数的更新。在函数中，模型的前向阶段是在<code>loss = self.model(data)</code>这行代码中进行的，模型的后向阶段是在<code>self.accelerator.backward(loss)</code>这行代码中进行的。最后，参数的更新是在<code>self.opt.step()</code>这行代码中进行的。在<code>train</code>函数的最后，当达到保存和采样的步数时，会调用<code>self.ema.ema_model.sample(batch_size=n)</code>生成样本，并保存到文件中，这部分对应于生成保存的生成文件。</p>
<div class="highlight"><pre><span></span><code>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">accelerator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>

        <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">initial</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_num_steps</span><span class="p">,</span> <span class="n">disable</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>

            <span class="k">while</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_num_steps</span><span class="p">:</span>

                <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.</span>

                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gradient_accumulate_every</span><span class="p">):</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dl</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">autocast</span><span class="p">():</span>
                        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient_accumulate_every</span>
                        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

                <span class="n">accelerator</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_grad_norm</span><span class="p">)</span>
                <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

                <span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="n">accelerator</span><span class="o">.</span><span class="n">wait_for_everyone</span><span class="p">()</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">divisible_by</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_and_sample_every</span><span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="o">.</span><span class="n">ema_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

                        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
                            <span class="n">milestone</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_and_sample_every</span>
                            <span class="n">batches</span> <span class="o">=</span> <span class="n">num_to_groups</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
                            <span class="n">all_images_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="o">.</span><span class="n">ema_model</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">n</span><span class="p">),</span> <span class="n">batches</span><span class="p">))</span>

                        <span class="n">all_images</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_images_list</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

                        <span class="n">utils</span><span class="o">.</span><span class="n">save_image</span><span class="p">(</span><span class="n">all_images</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">results_folder</span> <span class="o">/</span> <span class="sa">f</span><span class="s1">&#39;sample-</span><span class="si">{</span><span class="n">milestone</span><span class="si">}</span><span class="s1">.png&#39;</span><span class="p">),</span> <span class="n">nrow</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">)))</span>

                        <span class="c1"># whether to calculate fid</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_fid</span><span class="p">:</span>
                            <span class="n">fid_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fid_scorer</span><span class="o">.</span><span class="n">fid_score</span><span class="p">()</span>
                            <span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;fid_score: </span><span class="si">{</span><span class="n">fid_score</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_best_and_latest_only</span><span class="p">:</span>
                            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_fid</span> <span class="o">&gt;</span> <span class="n">fid_score</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">best_fid</span> <span class="o">=</span> <span class="n">fid_score</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;best&quot;</span><span class="p">)</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;latest&quot;</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">milestone</span><span class="p">)</span>

                <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">accelerator</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="s1">&#39;training complete&#39;</span><span class="p">)</span>
</code></pre></div>
<p>与一维逻辑基本相同，但在保存模型部分保存最优分数模型和最新模型。（主要是因为一维模型缺少度量机制）</p>
<h2 id="gaussiandiffusion">GaussianDiffusion<a class="headerlink" href="#gaussiandiffusion" title="Permanent link">&para;</a></h2>
<p>代码大致运行流程：</p>
<ol>
<li>
<p><code>__init__</code>：初始化函数，用于设置模型的参数，计算beta和alpha值，初始化模型、优化器和数据加载器，根据<code>objective</code>参数计算损失权重，根据<code>auto_normalize</code>参数选择是否自动归一化。这个函数在创建类的实例时运行。</p>
</li>
<li>
<p><code>forward</code>：前向传播函数，用于计算损失。这个函数在训练模型时运行，它会调用<code>p_losses</code>函数来计算损失。</p>
</li>
<li>
<p><code>p_losses</code>：计算损失函数，它会生成噪声，然后从起始图像和噪声中采样，得到一个新的图像。然后，根据<code>self_condition</code>参数决定是否进行自我条件化，然后调用<code>model_predictions</code>函数计算模型预测。最后，根据<code>objective</code>参数计算损失。这个函数在<code>forward</code>函数中被调用。</p>
</li>
<li>
<p><code>model_predictions</code>：计算模型预测函数，它会根据<code>objective</code>参数调用相应的函数（<code>predict_start_from_noise</code>、<code>predict_noise_from_start</code>或<code>predict_v</code>）计算模型预测。这个函数在<code>p_losses</code>函数中被调用。</p>
</li>
<li>
<p><code>p_sample</code>：采样函数，用于生成新的图像。这个函数在生成新的图像时运行，它会被<code>p_sample_loop</code>、<code>ddim_sample</code>和<code>sample</code>函数调用。</p>
</li>
<li>
<p><code>p_sample_loop</code>：循环采样函数，它会在一个循环中多次调用<code>p_sample</code>函数进行采样。这个函数在<code>sample</code>函数中被调用。</p>
</li>
<li>
<p><code>ddim_sample</code>：DDIM采样函数，它会在一个循环中多次调用<code>p_sample</code>函数进行DDIM采样。这个函数在<code>sample</code>函数中被调用。</p>
</li>
<li>
<p><code>sample</code>：采样函数，它会根据<code>is_ddim_sampling</code>参数选择采样函数（<code>p_sample_loop</code>或<code>ddim_sample</code>）。这个函数在生成新的图像时运行。</p>
</li>
<li>
<p><code>interpolate</code>：插值函数，它会在一个循环中多次调用<code>p_sample</code>函数进行插值。这个函数在生成插值图像时运行。</p>
</li>
<li>
<p><code>q_sample</code>：采样函数，它会从起始图像和噪声中采样，得到一个新的图像。这个函数在<code>p_losses</code>和<code>interpolate</code>函数中被调用。</p>
</li>
</ol>
<p>具体来说，在 <code>GaussianDiffusion</code> 类中，<code>forward</code> 函数是模型的主要入口，它负责在前向过程中添加噪声，并在后向过程中计算损失。</p>
<p>在前向过程中，<code>forward</code> 函数首先将输入图像正则化，然后调用 <code>p_losses</code> 函数。在 <code>p_losses</code> 函数中，首先生成一个与输入图像形状相同的随机噪声，然后调用 <code>q_sample</code> 函数，该函数将噪声添加到输入图像中，生成一个新的图像。这就是在前向过程中添加噪声的部分。</p>
<p>在后向过程中，<code>p_losses</code> 函数继续执行，它调用模型的 <code>model_predictions</code> 函数来预测噪声，然后计算预测噪声和实际噪声之间的均方误差损失。这个损失被乘以一个损失权重，然后返回给 <code>forward</code> 函数，<code>forward</code> 函数将这个损失返回给调用者。这就是在后向过程中计算损失的部分。</p>
<h3 id="一维_3">一维<a class="headerlink" href="#一维_3" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">GaussianDiffusion1D</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">seq_length</span><span class="p">,</span>
        <span class="n">timesteps</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">sampling_timesteps</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span> <span class="o">=</span> <span class="s1">&#39;pred_noise&#39;</span><span class="p">,</span>
        <span class="n">beta_schedule</span> <span class="o">=</span> <span class="s1">&#39;cosine&#39;</span><span class="p">,</span>
        <span class="n">ddim_sampling_eta</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span>
        <span class="n">auto_normalize</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">self_condition</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">self_condition</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">seq_length</span> <span class="o">=</span> <span class="n">seq_length</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">=</span> <span class="n">objective</span>

        <span class="k">assert</span> <span class="n">objective</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;pred_noise&#39;</span><span class="p">,</span> <span class="s1">&#39;pred_x0&#39;</span><span class="p">,</span> <span class="s1">&#39;pred_v&#39;</span><span class="p">},</span> <span class="s1">&#39;objective must be either pred_noise (predict noise) or pred_x0 (predict image start) or pred_v (predict v [v-parameterization as defined in appendix D of progressive distillation paper, used in imagen-video successfully])&#39;</span>

        <span class="k">if</span> <span class="n">beta_schedule</span> <span class="o">==</span> <span class="s1">&#39;linear&#39;</span><span class="p">:</span>
            <span class="n">betas</span> <span class="o">=</span> <span class="n">linear_beta_schedule</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">beta_schedule</span> <span class="o">==</span> <span class="s1">&#39;cosine&#39;</span><span class="p">:</span>
            <span class="n">betas</span> <span class="o">=</span> <span class="n">cosine_beta_schedule</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;unknown beta schedule </span><span class="si">{</span><span class="n">beta_schedule</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="n">alphas</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">-</span> <span class="n">betas</span>
        <span class="n">alphas_cumprod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">alphas_cumprod_prev</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">alphas_cumprod</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">value</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">)</span>

        <span class="n">timesteps</span><span class="p">,</span> <span class="o">=</span> <span class="n">betas</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_timesteps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span>

        <span class="c1"># sampling related parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sampling_timesteps</span> <span class="o">=</span> <span class="n">default</span><span class="p">(</span><span class="n">sampling_timesteps</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span> <span class="c1"># default num sampling timesteps to number of timesteps at training</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampling_timesteps</span> <span class="o">&lt;=</span> <span class="n">timesteps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_ddim_sampling</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampling_timesteps</span> <span class="o">&lt;</span> <span class="n">timesteps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ddim_sampling_eta</span> <span class="o">=</span> <span class="n">ddim_sampling_eta</span>

        <span class="c1"># helper function to register buffer from float64 to float32</span>
        <span class="n">register_buffer</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">val</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;betas&#39;</span><span class="p">,</span> <span class="n">betas</span><span class="p">)</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;alphas_cumprod&#39;</span><span class="p">,</span> <span class="n">alphas_cumprod</span><span class="p">)</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;alphas_cumprod_prev&#39;</span><span class="p">,</span> <span class="n">alphas_cumprod_prev</span><span class="p">)</span>

        <span class="c1"># calculations for diffusion q(x_t | x_{t-1}) and others</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;sqrt_alphas_cumprod&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_cumprod</span><span class="p">))</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;sqrt_one_minus_alphas_cumprod&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">))</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;log_one_minus_alphas_cumprod&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">))</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;sqrt_recip_alphas_cumprod&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">alphas_cumprod</span><span class="p">))</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;sqrt_recipm1_alphas_cumprod&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">alphas_cumprod</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># calculations for posterior q(x_{t-1} | x_t, x_0)</span>
        <span class="n">posterior_variance</span> <span class="o">=</span> <span class="n">betas</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod_prev</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">)</span>

        <span class="c1"># above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;posterior_variance&#39;</span><span class="p">,</span> <span class="n">posterior_variance</span><span class="p">)</span>

        <span class="c1"># below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;posterior_log_variance_clipped&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">posterior_variance</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span> <span class="o">=</span><span class="mf">1e-20</span><span class="p">)))</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;posterior_mean_coef1&#39;</span><span class="p">,</span> <span class="n">betas</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_cumprod_prev</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">))</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;posterior_mean_coef2&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod_prev</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">))</span>

        <span class="c1"># calculate loss weight</span>

        <span class="n">snr</span> <span class="o">=</span> <span class="n">alphas_cumprod</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">objective</span> <span class="o">==</span> <span class="s1">&#39;pred_noise&#39;</span><span class="p">:</span>
            <span class="n">loss_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">snr</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">objective</span> <span class="o">==</span> <span class="s1">&#39;pred_x0&#39;</span><span class="p">:</span>
            <span class="n">loss_weight</span> <span class="o">=</span> <span class="n">snr</span>
        <span class="k">elif</span> <span class="n">objective</span> <span class="o">==</span> <span class="s1">&#39;pred_v&#39;</span><span class="p">:</span>
            <span class="n">loss_weight</span> <span class="o">=</span> <span class="n">snr</span> <span class="o">/</span> <span class="p">(</span><span class="n">snr</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;loss_weight&#39;</span><span class="p">,</span> <span class="n">loss_weight</span><span class="p">)</span>

        <span class="c1"># whether to autonormalize</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize_to_neg_one_to_one</span> <span class="k">if</span> <span class="n">auto_normalize</span> <span class="k">else</span> <span class="n">identity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unnormalize</span> <span class="o">=</span> <span class="n">unnormalize_to_zero_to_one</span> <span class="k">if</span> <span class="n">auto_normalize</span> <span class="k">else</span> <span class="n">identity</span>

    <span class="k">def</span> <span class="nf">predict_start_from_noise</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_recip_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_t</span> <span class="o">-</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_recipm1_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">noise</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict_noise_from_start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x0</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_recip_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_t</span> <span class="o">-</span> <span class="n">x0</span><span class="p">)</span> <span class="o">/</span> \
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_recipm1_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict_v</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_start</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">noise</span> <span class="o">-</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_one_minus_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_start</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_start</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict_start_from_v</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_t</span> <span class="o">-</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_one_minus_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">v</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">q_posterior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">posterior_mean</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_mean_coef1</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_start</span> <span class="o">+</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_mean_coef2</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_t</span>
        <span class="p">)</span>
        <span class="n">posterior_variance</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_variance</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">posterior_log_variance_clipped</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_log_variance_clipped</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">posterior_mean</span><span class="p">,</span> <span class="n">posterior_variance</span><span class="p">,</span> <span class="n">posterior_log_variance_clipped</span>

    <span class="k">def</span> <span class="nf">model_predictions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_self_cond</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">clip_x_start</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">rederive_pred_noise</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="n">model_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_self_cond</span><span class="p">)</span>
        <span class="n">maybe_clip</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">,</span> <span class="nb">min</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="nb">max</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">)</span> <span class="k">if</span> <span class="n">clip_x_start</span> <span class="k">else</span> <span class="n">identity</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">==</span> <span class="s1">&#39;pred_noise&#39;</span><span class="p">:</span>
            <span class="n">pred_noise</span> <span class="o">=</span> <span class="n">model_output</span>
            <span class="n">x_start</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_start_from_noise</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">pred_noise</span><span class="p">)</span>
            <span class="n">x_start</span> <span class="o">=</span> <span class="n">maybe_clip</span><span class="p">(</span><span class="n">x_start</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">clip_x_start</span> <span class="ow">and</span> <span class="n">rederive_pred_noise</span><span class="p">:</span>
                <span class="n">pred_noise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_noise_from_start</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_start</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">==</span> <span class="s1">&#39;pred_x0&#39;</span><span class="p">:</span>
            <span class="n">x_start</span> <span class="o">=</span> <span class="n">model_output</span>
            <span class="n">x_start</span> <span class="o">=</span> <span class="n">maybe_clip</span><span class="p">(</span><span class="n">x_start</span><span class="p">)</span>
            <span class="n">pred_noise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_noise_from_start</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_start</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">==</span> <span class="s1">&#39;pred_v&#39;</span><span class="p">:</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">model_output</span>
            <span class="n">x_start</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_start_from_v</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
            <span class="n">x_start</span> <span class="o">=</span> <span class="n">maybe_clip</span><span class="p">(</span><span class="n">x_start</span><span class="p">)</span>
            <span class="n">pred_noise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_noise_from_start</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_start</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ModelPrediction</span><span class="p">(</span><span class="n">pred_noise</span><span class="p">,</span> <span class="n">x_start</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">p_mean_variance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_self_cond</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">clip_denoised</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_predictions</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_self_cond</span><span class="p">)</span>
        <span class="n">x_start</span> <span class="o">=</span> <span class="n">preds</span><span class="o">.</span><span class="n">pred_x_start</span>

        <span class="k">if</span> <span class="n">clip_denoised</span><span class="p">:</span>
            <span class="n">x_start</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>

        <span class="n">model_mean</span><span class="p">,</span> <span class="n">posterior_variance</span><span class="p">,</span> <span class="n">posterior_log_variance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_posterior</span><span class="p">(</span><span class="n">x_start</span> <span class="o">=</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">x_t</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model_mean</span><span class="p">,</span> <span class="n">posterior_variance</span><span class="p">,</span> <span class="n">posterior_log_variance</span><span class="p">,</span> <span class="n">x_start</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">p_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">x_self_cond</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">clip_denoised</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span>
        <span class="n">batched_times</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">b</span><span class="p">,),</span> <span class="n">t</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="n">model_mean</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">model_log_variance</span><span class="p">,</span> <span class="n">x_start</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_mean_variance</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">batched_times</span><span class="p">,</span> <span class="n">x_self_cond</span> <span class="o">=</span> <span class="n">x_self_cond</span><span class="p">,</span> <span class="n">clip_denoised</span> <span class="o">=</span> <span class="n">clip_denoised</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">if</span> <span class="n">t</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.</span> <span class="c1"># no noise if t == 0</span>
        <span class="n">pred_img</span> <span class="o">=</span> <span class="n">model_mean</span> <span class="o">+</span> <span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">model_log_variance</span><span class="p">)</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span> <span class="o">*</span> <span class="n">noise</span>
        <span class="k">return</span> <span class="n">pred_img</span><span class="p">,</span> <span class="n">x_start</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">p_sample_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
        <span class="n">batch</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="o">.</span><span class="n">device</span>

        <span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

        <span class="n">x_start</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_timesteps</span><span class="p">)),</span> <span class="n">desc</span> <span class="o">=</span> <span class="s1">&#39;sampling loop time step&#39;</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_timesteps</span><span class="p">):</span>
            <span class="n">self_cond</span> <span class="o">=</span> <span class="n">x_start</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_condition</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="n">img</span><span class="p">,</span> <span class="n">x_start</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_sample</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">self_cond</span><span class="p">)</span>

        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unnormalize</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">ddim_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">clip_denoised</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">total_timesteps</span><span class="p">,</span> <span class="n">sampling_timesteps</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">objective</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_timesteps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampling_timesteps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ddim_sampling_eta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span>

        <span class="n">times</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_timesteps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="n">sampling_timesteps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>   <span class="c1"># [-1, 0, 1, 2, ..., T-1] when sampling_timesteps == total_timesteps</span>
        <span class="n">times</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">times</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
        <span class="n">time_pairs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">times</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">times</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span> <span class="c1"># [(T-1, T-2), (T-2, T-3), ..., (1, 0), (0, -1)]</span>

        <span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>

        <span class="n">x_start</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">time</span><span class="p">,</span> <span class="n">time_next</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">time_pairs</span><span class="p">,</span> <span class="n">desc</span> <span class="o">=</span> <span class="s1">&#39;sampling loop time step&#39;</span><span class="p">):</span>
            <span class="n">time_cond</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">batch</span><span class="p">,),</span> <span class="n">time</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
            <span class="n">self_cond</span> <span class="o">=</span> <span class="n">x_start</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_condition</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="n">pred_noise</span><span class="p">,</span> <span class="n">x_start</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_predictions</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">time_cond</span><span class="p">,</span> <span class="n">self_cond</span><span class="p">,</span> <span class="n">clip_x_start</span> <span class="o">=</span> <span class="n">clip_denoised</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">time_next</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">img</span> <span class="o">=</span> <span class="n">x_start</span>
                <span class="k">continue</span>

            <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas_cumprod</span><span class="p">[</span><span class="n">time</span><span class="p">]</span>
            <span class="n">alpha_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas_cumprod</span><span class="p">[</span><span class="n">time_next</span><span class="p">]</span>

            <span class="n">sigma</span> <span class="o">=</span> <span class="n">eta</span> <span class="o">*</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">/</span> <span class="n">alpha_next</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha_next</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">))</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
            <span class="n">c</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha_next</span> <span class="o">-</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>

            <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

            <span class="n">img</span> <span class="o">=</span> <span class="n">x_start</span> <span class="o">*</span> <span class="n">alpha_next</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span> <span class="o">+</span> \
                  <span class="n">c</span> <span class="o">*</span> <span class="n">pred_noise</span> <span class="o">+</span> \
                  <span class="n">sigma</span> <span class="o">*</span> <span class="n">noise</span>

        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unnormalize</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span><span class="p">):</span>
        <span class="n">seq_length</span><span class="p">,</span> <span class="n">channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">channels</span>
        <span class="n">sample_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_sample_loop</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_ddim_sampling</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">ddim_sample</span>
        <span class="k">return</span> <span class="n">sample_fn</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">))</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">interpolate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">lam</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="o">*</span><span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x1</span><span class="o">.</span><span class="n">device</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">default</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_timesteps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">assert</span> <span class="n">x1</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">x2</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">t_batched</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">b</span><span class="p">,),</span> <span class="n">t</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">xt1</span><span class="p">,</span> <span class="n">xt2</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_sample</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">t_batched</span><span class="p">),</span> <span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">))</span>

        <span class="n">img</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">lam</span><span class="p">)</span> <span class="o">*</span> <span class="n">xt1</span> <span class="o">+</span> <span class="n">lam</span> <span class="o">*</span> <span class="n">xt2</span>

        <span class="n">x_start</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">)),</span> <span class="n">desc</span> <span class="o">=</span> <span class="s1">&#39;interpolation sample time step&#39;</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="n">t</span><span class="p">):</span>
            <span class="n">self_cond</span> <span class="o">=</span> <span class="n">x_start</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_condition</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="n">img</span><span class="p">,</span> <span class="n">x_start</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_sample</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">self_cond</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">img</span>

    <span class="nd">@autocast</span><span class="p">(</span><span class="n">enabled</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">q_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">default</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x_start</span><span class="p">))</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_start</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_start</span> <span class="o">+</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_one_minus_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_start</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">noise</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">p_losses</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">x_start</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">default</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x_start</span><span class="p">))</span>

        <span class="c1"># noise sample</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_sample</span><span class="p">(</span><span class="n">x_start</span> <span class="o">=</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span> <span class="o">=</span> <span class="n">noise</span><span class="p">)</span>

        <span class="c1"># if doing self-conditioning, 50% of the time, predict x_start from current set of times</span>
        <span class="c1"># and condition with unet with that</span>
        <span class="c1"># this technique will slow down training by 25%, but seems to lower FID significantly</span>

        <span class="n">x_self_cond</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_condition</span> <span class="ow">and</span> <span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">x_self_cond</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_predictions</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span><span class="o">.</span><span class="n">pred_x_start</span>
                <span class="n">x_self_cond</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span>

        <span class="c1"># predict and take gradient step</span>

        <span class="n">model_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_self_cond</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">==</span> <span class="s1">&#39;pred_noise&#39;</span><span class="p">:</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">noise</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">==</span> <span class="s1">&#39;pred_x0&#39;</span><span class="p">:</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">x_start</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">==</span> <span class="s1">&#39;pred_v&#39;</span><span class="p">:</span>
            <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_v</span><span class="p">(</span><span class="n">x_start</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span><span class="p">)</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">v</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;unknown objective </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">model_out</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;none&#39;</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">reduce</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;b ... -&gt; b (...)&#39;</span><span class="p">,</span> <span class="s1">&#39;mean&#39;</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">*</span> <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_weight</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">,</span> <span class="o">=</span> <span class="o">*</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_length</span>
        <span class="k">assert</span> <span class="n">n</span> <span class="o">==</span> <span class="n">seq_length</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;seq length must be </span><span class="si">{</span><span class="n">seq_length</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_timesteps</span><span class="p">,</span> <span class="p">(</span><span class="n">b</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_losses</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
<h3 id="多维_3">多维<a class="headerlink" href="#多维_3" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">GaussianDiffusion</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">image_size</span><span class="p">,</span>
        <span class="n">timesteps</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">sampling_timesteps</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">objective</span> <span class="o">=</span> <span class="s1">&#39;pred_v&#39;</span><span class="p">,</span>
        <span class="n">beta_schedule</span> <span class="o">=</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span>
        <span class="n">schedule_fn_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(),</span>
        <span class="n">ddim_sampling_eta</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span>
        <span class="n">auto_normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">offset_noise_strength</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span>  <span class="c1"># https://www.crosslabs.org/blog/diffusion-with-offset-noise</span>
        <span class="n">min_snr_loss_weight</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="c1"># https://arxiv.org/abs/2303.09556</span>
        <span class="n">min_snr_gamma</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">==</span> <span class="n">GaussianDiffusion</span> <span class="ow">and</span> <span class="n">model</span><span class="o">.</span><span class="n">channels</span> <span class="o">!=</span> <span class="n">model</span><span class="o">.</span><span class="n">out_dim</span><span class="p">)</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">model</span><span class="o">.</span><span class="n">random_or_learned_sinusoidal_cond</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">self_condition</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">self_condition</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span> <span class="o">=</span> <span class="n">image_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">=</span> <span class="n">objective</span>

        <span class="k">assert</span> <span class="n">objective</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;pred_noise&#39;</span><span class="p">,</span> <span class="s1">&#39;pred_x0&#39;</span><span class="p">,</span> <span class="s1">&#39;pred_v&#39;</span><span class="p">},</span> <span class="s1">&#39;objective must be either pred_noise (predict noise) or pred_x0 (predict image start) or pred_v (predict v [v-parameterization as defined in appendix D of progressive distillation paper, used in imagen-video successfully])&#39;</span>

        <span class="k">if</span> <span class="n">beta_schedule</span> <span class="o">==</span> <span class="s1">&#39;linear&#39;</span><span class="p">:</span>
            <span class="n">beta_schedule_fn</span> <span class="o">=</span> <span class="n">linear_beta_schedule</span>
        <span class="k">elif</span> <span class="n">beta_schedule</span> <span class="o">==</span> <span class="s1">&#39;cosine&#39;</span><span class="p">:</span>
            <span class="n">beta_schedule_fn</span> <span class="o">=</span> <span class="n">cosine_beta_schedule</span>
        <span class="k">elif</span> <span class="n">beta_schedule</span> <span class="o">==</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span>
            <span class="n">beta_schedule_fn</span> <span class="o">=</span> <span class="n">sigmoid_beta_schedule</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;unknown beta schedule </span><span class="si">{</span><span class="n">beta_schedule</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="n">betas</span> <span class="o">=</span> <span class="n">beta_schedule_fn</span><span class="p">(</span><span class="n">timesteps</span><span class="p">,</span> <span class="o">**</span><span class="n">schedule_fn_kwargs</span><span class="p">)</span>

        <span class="n">alphas</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">-</span> <span class="n">betas</span>
        <span class="n">alphas_cumprod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">alphas_cumprod_prev</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">alphas_cumprod</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">value</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">)</span>

        <span class="n">timesteps</span><span class="p">,</span> <span class="o">=</span> <span class="n">betas</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_timesteps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span>

        <span class="c1"># sampling related parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sampling_timesteps</span> <span class="o">=</span> <span class="n">default</span><span class="p">(</span><span class="n">sampling_timesteps</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span> <span class="c1"># default num sampling timesteps to number of timesteps at training</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampling_timesteps</span> <span class="o">&lt;=</span> <span class="n">timesteps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_ddim_sampling</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampling_timesteps</span> <span class="o">&lt;</span> <span class="n">timesteps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ddim_sampling_eta</span> <span class="o">=</span> <span class="n">ddim_sampling_eta</span>

        <span class="c1"># helper function to register buffer from float64 to float32</span>
        <span class="n">register_buffer</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">val</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;betas&#39;</span><span class="p">,</span> <span class="n">betas</span><span class="p">)</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;alphas_cumprod&#39;</span><span class="p">,</span> <span class="n">alphas_cumprod</span><span class="p">)</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;alphas_cumprod_prev&#39;</span><span class="p">,</span> <span class="n">alphas_cumprod_prev</span><span class="p">)</span>

        <span class="c1"># calculations for diffusion q(x_t | x_{t-1}) and others</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;sqrt_alphas_cumprod&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_cumprod</span><span class="p">))</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;sqrt_one_minus_alphas_cumprod&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">))</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;log_one_minus_alphas_cumprod&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">))</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;sqrt_recip_alphas_cumprod&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">alphas_cumprod</span><span class="p">))</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;sqrt_recipm1_alphas_cumprod&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">alphas_cumprod</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># calculations for posterior q(x_{t-1} | x_t, x_0)</span>
        <span class="n">posterior_variance</span> <span class="o">=</span> <span class="n">betas</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod_prev</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">)</span>

        <span class="c1"># above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;posterior_variance&#39;</span><span class="p">,</span> <span class="n">posterior_variance</span><span class="p">)</span>

        <span class="c1"># below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;posterior_log_variance_clipped&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">posterior_variance</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span> <span class="o">=</span><span class="mf">1e-20</span><span class="p">)))</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;posterior_mean_coef1&#39;</span><span class="p">,</span> <span class="n">betas</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_cumprod_prev</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">))</span>
        <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;posterior_mean_coef2&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod_prev</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">))</span>

        <span class="c1"># offset noise strength - in blogpost, they claimed 0.1 was ideal</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">offset_noise_strength</span> <span class="o">=</span> <span class="n">offset_noise_strength</span>

        <span class="c1"># derive loss weight</span>
        <span class="c1"># snr - signal noise ratio</span>
        <span class="n">snr</span> <span class="o">=</span> <span class="n">alphas_cumprod</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">)</span>

        <span class="c1"># https://arxiv.org/abs/2303.09556</span>
        <span class="n">maybe_clipped_snr</span> <span class="o">=</span> <span class="n">snr</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">min_snr_loss_weight</span><span class="p">:</span>
            <span class="n">maybe_clipped_snr</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="nb">max</span> <span class="o">=</span> <span class="n">min_snr_gamma</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">objective</span> <span class="o">==</span> <span class="s1">&#39;pred_noise&#39;</span><span class="p">:</span>
            <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;loss_weight&#39;</span><span class="p">,</span> <span class="n">maybe_clipped_snr</span> <span class="o">/</span> <span class="n">snr</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">objective</span> <span class="o">==</span> <span class="s1">&#39;pred_x0&#39;</span><span class="p">:</span>
            <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;loss_weight&#39;</span><span class="p">,</span> <span class="n">maybe_clipped_snr</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">objective</span> <span class="o">==</span> <span class="s1">&#39;pred_v&#39;</span><span class="p">:</span>
            <span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;loss_weight&#39;</span><span class="p">,</span> <span class="n">maybe_clipped_snr</span> <span class="o">/</span> <span class="p">(</span><span class="n">snr</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># auto-normalization of data [0, 1] -&gt; [-1, 1] - can turn off by setting it to be False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize_to_neg_one_to_one</span> <span class="k">if</span> <span class="n">auto_normalize</span> <span class="k">else</span> <span class="n">identity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unnormalize</span> <span class="o">=</span> <span class="n">unnormalize_to_zero_to_one</span> <span class="k">if</span> <span class="n">auto_normalize</span> <span class="k">else</span> <span class="n">identity</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">betas</span><span class="o">.</span><span class="n">device</span>

    <span class="k">def</span> <span class="nf">predict_start_from_noise</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_recip_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_t</span> <span class="o">-</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_recipm1_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">noise</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict_noise_from_start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x0</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_recip_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_t</span> <span class="o">-</span> <span class="n">x0</span><span class="p">)</span> <span class="o">/</span> \
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_recipm1_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict_v</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_start</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">noise</span> <span class="o">-</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_one_minus_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_start</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_start</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict_start_from_v</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_t</span> <span class="o">-</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_one_minus_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">v</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">q_posterior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="n">posterior_mean</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_mean_coef1</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_start</span> <span class="o">+</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_mean_coef2</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_t</span>
        <span class="p">)</span>
        <span class="n">posterior_variance</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_variance</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">posterior_log_variance_clipped</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">posterior_log_variance_clipped</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">posterior_mean</span><span class="p">,</span> <span class="n">posterior_variance</span><span class="p">,</span> <span class="n">posterior_log_variance_clipped</span>

    <span class="k">def</span> <span class="nf">model_predictions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_self_cond</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">clip_x_start</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">rederive_pred_noise</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="n">model_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_self_cond</span><span class="p">)</span>
        <span class="n">maybe_clip</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">,</span> <span class="nb">min</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="nb">max</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">)</span> <span class="k">if</span> <span class="n">clip_x_start</span> <span class="k">else</span> <span class="n">identity</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">==</span> <span class="s1">&#39;pred_noise&#39;</span><span class="p">:</span>
            <span class="n">pred_noise</span> <span class="o">=</span> <span class="n">model_output</span>
            <span class="n">x_start</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_start_from_noise</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">pred_noise</span><span class="p">)</span>
            <span class="n">x_start</span> <span class="o">=</span> <span class="n">maybe_clip</span><span class="p">(</span><span class="n">x_start</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">clip_x_start</span> <span class="ow">and</span> <span class="n">rederive_pred_noise</span><span class="p">:</span>
                <span class="n">pred_noise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_noise_from_start</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_start</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">==</span> <span class="s1">&#39;pred_x0&#39;</span><span class="p">:</span>
            <span class="n">x_start</span> <span class="o">=</span> <span class="n">model_output</span>
            <span class="n">x_start</span> <span class="o">=</span> <span class="n">maybe_clip</span><span class="p">(</span><span class="n">x_start</span><span class="p">)</span>
            <span class="n">pred_noise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_noise_from_start</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_start</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">==</span> <span class="s1">&#39;pred_v&#39;</span><span class="p">:</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">model_output</span>
            <span class="n">x_start</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_start_from_v</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
            <span class="n">x_start</span> <span class="o">=</span> <span class="n">maybe_clip</span><span class="p">(</span><span class="n">x_start</span><span class="p">)</span>
            <span class="n">pred_noise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_noise_from_start</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_start</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ModelPrediction</span><span class="p">(</span><span class="n">pred_noise</span><span class="p">,</span> <span class="n">x_start</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">p_mean_variance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_self_cond</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">clip_denoised</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_predictions</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_self_cond</span><span class="p">)</span>
        <span class="n">x_start</span> <span class="o">=</span> <span class="n">preds</span><span class="o">.</span><span class="n">pred_x_start</span>

        <span class="k">if</span> <span class="n">clip_denoised</span><span class="p">:</span>
            <span class="n">x_start</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>

        <span class="n">model_mean</span><span class="p">,</span> <span class="n">posterior_variance</span><span class="p">,</span> <span class="n">posterior_log_variance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_posterior</span><span class="p">(</span><span class="n">x_start</span> <span class="o">=</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">x_t</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model_mean</span><span class="p">,</span> <span class="n">posterior_variance</span><span class="p">,</span> <span class="n">posterior_log_variance</span><span class="p">,</span> <span class="n">x_start</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">p_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">x_self_cond</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>
        <span class="n">batched_times</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">b</span><span class="p">,),</span> <span class="n">t</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="n">model_mean</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">model_log_variance</span><span class="p">,</span> <span class="n">x_start</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_mean_variance</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">batched_times</span><span class="p">,</span> <span class="n">x_self_cond</span> <span class="o">=</span> <span class="n">x_self_cond</span><span class="p">,</span> <span class="n">clip_denoised</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">if</span> <span class="n">t</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.</span> <span class="c1"># no noise if t == 0</span>
        <span class="n">pred_img</span> <span class="o">=</span> <span class="n">model_mean</span> <span class="o">+</span> <span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">model_log_variance</span><span class="p">)</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span> <span class="o">*</span> <span class="n">noise</span>
        <span class="k">return</span> <span class="n">pred_img</span><span class="p">,</span> <span class="n">x_start</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">p_sample_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">return_all_timesteps</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="n">batch</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span>

        <span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">imgs</span> <span class="o">=</span> <span class="p">[</span><span class="n">img</span><span class="p">]</span>

        <span class="n">x_start</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_timesteps</span><span class="p">)),</span> <span class="n">desc</span> <span class="o">=</span> <span class="s1">&#39;sampling loop time step&#39;</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_timesteps</span><span class="p">):</span>
            <span class="n">self_cond</span> <span class="o">=</span> <span class="n">x_start</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_condition</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="n">img</span><span class="p">,</span> <span class="n">x_start</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_sample</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">self_cond</span><span class="p">)</span>
            <span class="n">imgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

        <span class="n">ret</span> <span class="o">=</span> <span class="n">img</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all_timesteps</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unnormalize</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ret</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">ddim_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">return_all_timesteps</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">total_timesteps</span><span class="p">,</span> <span class="n">sampling_timesteps</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span> <span class="n">objective</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_timesteps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampling_timesteps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ddim_sampling_eta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span>

        <span class="n">times</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_timesteps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">steps</span> <span class="o">=</span> <span class="n">sampling_timesteps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>   <span class="c1"># [-1, 0, 1, 2, ..., T-1] when sampling_timesteps == total_timesteps</span>
        <span class="n">times</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">times</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
        <span class="n">time_pairs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">times</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">times</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span> <span class="c1"># [(T-1, T-2), (T-2, T-3), ..., (1, 0), (0, -1)]</span>

        <span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">imgs</span> <span class="o">=</span> <span class="p">[</span><span class="n">img</span><span class="p">]</span>

        <span class="n">x_start</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">time</span><span class="p">,</span> <span class="n">time_next</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">time_pairs</span><span class="p">,</span> <span class="n">desc</span> <span class="o">=</span> <span class="s1">&#39;sampling loop time step&#39;</span><span class="p">):</span>
            <span class="n">time_cond</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">batch</span><span class="p">,),</span> <span class="n">time</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
            <span class="n">self_cond</span> <span class="o">=</span> <span class="n">x_start</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_condition</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="n">pred_noise</span><span class="p">,</span> <span class="n">x_start</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_predictions</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">time_cond</span><span class="p">,</span> <span class="n">self_cond</span><span class="p">,</span> <span class="n">clip_x_start</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">rederive_pred_noise</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">time_next</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">img</span> <span class="o">=</span> <span class="n">x_start</span>
                <span class="n">imgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
                <span class="k">continue</span>

            <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas_cumprod</span><span class="p">[</span><span class="n">time</span><span class="p">]</span>
            <span class="n">alpha_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas_cumprod</span><span class="p">[</span><span class="n">time_next</span><span class="p">]</span>

            <span class="n">sigma</span> <span class="o">=</span> <span class="n">eta</span> <span class="o">*</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">/</span> <span class="n">alpha_next</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha_next</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">))</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
            <span class="n">c</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha_next</span> <span class="o">-</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>

            <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

            <span class="n">img</span> <span class="o">=</span> <span class="n">x_start</span> <span class="o">*</span> <span class="n">alpha_next</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span> <span class="o">+</span> \
                  <span class="n">c</span> <span class="o">*</span> <span class="n">pred_noise</span> <span class="o">+</span> \
                  <span class="n">sigma</span> <span class="o">*</span> <span class="n">noise</span>

            <span class="n">imgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

        <span class="n">ret</span> <span class="o">=</span> <span class="n">img</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all_timesteps</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unnormalize</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ret</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span> <span class="n">return_all_timesteps</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="n">image_size</span><span class="p">,</span> <span class="n">channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">channels</span>
        <span class="n">sample_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_sample_loop</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_ddim_sampling</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">ddim_sample</span>
        <span class="k">return</span> <span class="n">sample_fn</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">),</span> <span class="n">return_all_timesteps</span> <span class="o">=</span> <span class="n">return_all_timesteps</span><span class="p">)</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">interpolate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">lam</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="o">*</span><span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x1</span><span class="o">.</span><span class="n">device</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">default</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_timesteps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">assert</span> <span class="n">x1</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">x2</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">t_batched</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">b</span><span class="p">,),</span> <span class="n">t</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
        <span class="n">xt1</span><span class="p">,</span> <span class="n">xt2</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_sample</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">t_batched</span><span class="p">),</span> <span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">))</span>

        <span class="n">img</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">lam</span><span class="p">)</span> <span class="o">*</span> <span class="n">xt1</span> <span class="o">+</span> <span class="n">lam</span> <span class="o">*</span> <span class="n">xt2</span>

        <span class="n">x_start</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">)),</span> <span class="n">desc</span> <span class="o">=</span> <span class="s1">&#39;interpolation sample time step&#39;</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="n">t</span><span class="p">):</span>
            <span class="n">self_cond</span> <span class="o">=</span> <span class="n">x_start</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_condition</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="n">img</span><span class="p">,</span> <span class="n">x_start</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_sample</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">self_cond</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">img</span>

    <span class="nd">@autocast</span><span class="p">(</span><span class="n">enabled</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">q_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">default</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x_start</span><span class="p">))</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_start</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_start</span> <span class="o">+</span>
            <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_one_minus_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_start</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">noise</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">p_losses</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">offset_noise_strength</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">x_start</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">noise</span> <span class="o">=</span> <span class="n">default</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x_start</span><span class="p">))</span>

        <span class="c1"># offset noise - https://www.crosslabs.org/blog/diffusion-with-offset-noise</span>

        <span class="n">offset_noise_strength</span> <span class="o">=</span> <span class="n">default</span><span class="p">(</span><span class="n">offset_noise_strength</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">offset_noise_strength</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">offset_noise_strength</span> <span class="o">&gt;</span> <span class="mf">0.</span><span class="p">:</span>
            <span class="n">offset_noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">x_start</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">noise</span> <span class="o">+=</span> <span class="n">offset_noise_strength</span> <span class="o">*</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">offset_noise</span><span class="p">,</span> <span class="s1">&#39;b c -&gt; b c 1 1&#39;</span><span class="p">)</span>

        <span class="c1"># noise sample</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_sample</span><span class="p">(</span><span class="n">x_start</span> <span class="o">=</span> <span class="n">x_start</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span> <span class="o">=</span> <span class="n">noise</span><span class="p">)</span>

        <span class="c1"># if doing self-conditioning, 50% of the time, predict x_start from current set of times</span>
        <span class="c1"># and condition with unet with that</span>
        <span class="c1"># this technique will slow down training by 25%, but seems to lower FID significantly</span>

        <span class="n">x_self_cond</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_condition</span> <span class="ow">and</span> <span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
                <span class="n">x_self_cond</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_predictions</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span><span class="o">.</span><span class="n">pred_x_start</span>
                <span class="n">x_self_cond</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span>

        <span class="c1"># predict and take gradient step</span>

        <span class="n">model_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_self_cond</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">==</span> <span class="s1">&#39;pred_noise&#39;</span><span class="p">:</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">noise</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">==</span> <span class="s1">&#39;pred_x0&#39;</span><span class="p">:</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">x_start</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span> <span class="o">==</span> <span class="s1">&#39;pred_v&#39;</span><span class="p">:</span>
            <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_v</span><span class="p">(</span><span class="n">x_start</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span><span class="p">)</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">v</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;unknown objective </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">model_out</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;none&#39;</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">reduce</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;b ... -&gt; b (...)&#39;</span><span class="p">,</span> <span class="s1">&#39;mean&#39;</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">*</span> <span class="n">extract</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_weight</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="o">=</span> <span class="o">*</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_size</span>
        <span class="k">assert</span> <span class="n">h</span> <span class="o">==</span> <span class="n">img_size</span> <span class="ow">and</span> <span class="n">w</span> <span class="o">==</span> <span class="n">img_size</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;height and width of image must be </span><span class="si">{</span><span class="n">img_size</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_timesteps</span><span class="p">,</span> <span class="p">(</span><span class="n">b</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_losses</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
<p><code>GaussianDiffusion</code>和<code>GaussianDiffusion1D</code>两个类的主要差异在于它们处理的数据维度不同。<code>GaussianDiffusion</code>类可以处理更高维度的数据，例如二维的图像数据，而<code>GaussianDiffusion1D</code>类只处理一维的数据。</p>
<p>以下是两个类中一些主要函数的差异和简化：</p>
<ol>
<li>
<p><code>__init__</code>函数：在<code>GaussianDiffusion</code>类中，这个函数需要处理的参数更多，包括图像的宽度和高度，而在<code>GaussianDiffusion1D</code>类中，由于只处理一维数据，所以这个函数的参数更少，只需要处理数据的长度。</p>
</li>
<li>
<p><code>p_sample</code>函数：在<code>GaussianDiffusion</code>类中，这个函数需要处理多个时间步，每个时间步都需要生成一个新的图像。而在<code>GaussianDiffusion1D</code>类中，这个函数只需要处理一个时间步，生成一个新的一维数据。</p>
</li>
<li>
<p><code>p_sample_loop</code>和<code>ddim_sample</code>函数：在<code>GaussianDiffusion</code>类中，这两个函数需要在一个循环中多次调用<code>p_sample</code>函数进行采样，每次采样都需要生成一个新的图像。而在<code>GaussianDiffusion1D</code>类中，这两个函数的实现更简单，只需要在一个循环中多次调用<code>p_sample</code>函数进行采样，每次采样都生成一个新的一维数据。</p>
</li>
<li>
<p><code>sample</code>函数：在<code>GaussianDiffusion</code>类中，这个函数需要根据<code>is_ddim_sampling</code>参数选择采样函数（<code>p_sample_loop</code>或<code>ddim_sample</code>），然后在一个循环中多次调用选定的采样函数进行采样，每次采样都需要生成一个新的图像。而在<code>GaussianDiffusion1D</code>类中，这个函数的实现更简单，只需要根据<code>is_ddim_sampling</code>参数选择采样函数（<code>p_sample_loop</code>或<code>ddim_sample</code>），然后在一个循环中多次调用选定的采样函数进行采样，每次采样都生成一个新的一维数据。</p>
</li>
</ol>
<h2 id="model">Model<a class="headerlink" href="#model" title="Permanent link">&para;</a></h2>
<p>在DDPM（Denoising Diffusion Probabilistic Models）模型中，<code>model</code>的目标可以是<code>pred_noise</code>、<code>pred_x0</code>或<code>pred_v</code>，这些选项代表了不同的预测目标，具体如下：</p>
<ol>
<li>
<p><code>pred_noise</code>：在这种情况下，<code>model</code>试图预测在每个时间步长应该添加的噪声。这是最直接的方法，因为在前向过程中，我们实际上是在每个步骤中添加噪声。然后在后向过程中，我们试图预测并去除这些噪声。</p>
</li>
<li>
<p><code>pred_x0</code>：在这种情况下，<code>model</code>试图预测原始图像（即噪声图像在完全去噪后的状态）。这是一个更具挑战性的任务，因为<code>model</code>需要在每个时间步长预测原始图像的全貌，即使在早期步骤中，噪声图像可能与原始图像差距很大。</p>
</li>
<li>
<p><code>pred_v</code>：这是一个更复杂的预测目标，它来自于DDPM的一种变体，称为Score-Based Generative Models。在这种情况下，<code>model</code>预测的是一个"score"，它是原始图像的梯度方向。这个"score"可以被看作是一个向量场，指向原始图像的方向。在后向过程中，我们可以沿着这个向量场的方向，逐步从噪声图像"移动"向原始图像。</p>
</li>
</ol>
<p>这三种预测目标提供了不同的方式来解决DDPM模型的重建任务。选择哪种预测目标取决于具体的应用需求和模型性能。</p>
<h3 id="construct">Construct<a class="headerlink" href="#construct" title="Permanent link">&para;</a></h3>
<h4 id="一维_4">一维<a class="headerlink" href="#一维_4" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">Residual</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fn</span> <span class="o">=</span> <span class="n">fn</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">+</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">Upsample</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim_out</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;nearest&#39;</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">default</span><span class="p">(</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">dim</span><span class="p">),</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span>

<span class="k">def</span> <span class="nf">Downsample</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim_out</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">default</span><span class="p">(</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">dim</span><span class="p">),</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">RMSNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">g</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">g</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">PreNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">fn</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fn</span> <span class="o">=</span> <span class="n">fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">RMSNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># sinusoidal positional embeds</span>

<span class="k">class</span> <span class="nc">SinusoidalPosEmb</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span>
        <span class="n">half_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">half_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">half_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="n">emb</span><span class="p">)</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">emb</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">emb</span><span class="o">.</span><span class="n">sin</span><span class="p">(),</span> <span class="n">emb</span><span class="o">.</span><span class="n">cos</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">emb</span>

<span class="k">class</span> <span class="nc">RandomOrLearnedSinusoidalPosEmb</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; following @crowsonkb &#39;s lead with random (learned optional) sinusoidal pos emb &quot;&quot;&quot;</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; https://github.com/crowsonkb/v-diffusion-jax/blob/master/diffusion/models/danbooru_128.py#L8 &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">is_random</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">assert</span> <span class="p">(</span><span class="n">dim</span> <span class="o">%</span> <span class="mi">2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="n">half_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">half_dim</span><span class="p">),</span> <span class="n">requires_grad</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">is_random</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;b -&gt; b 1&#39;</span><span class="p">)</span>
        <span class="n">freqs</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">rearrange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="s1">&#39;d -&gt; 1 d&#39;</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span>
        <span class="n">fouriered</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">freqs</span><span class="o">.</span><span class="n">sin</span><span class="p">(),</span> <span class="n">freqs</span><span class="o">.</span><span class="n">cos</span><span class="p">()),</span> <span class="n">dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">fouriered</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">fouriered</span><span class="p">),</span> <span class="n">dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fouriered</span>

<span class="c1"># building block modules</span>

<span class="k">class</span> <span class="nc">Block</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="mi">8</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">scale_shift</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">exists</span><span class="p">(</span><span class="n">scale_shift</span><span class="p">):</span>
            <span class="n">scale</span><span class="p">,</span> <span class="n">shift</span> <span class="o">=</span> <span class="n">scale_shift</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="n">scale</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">shift</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">class</span> <span class="nc">ResnetBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">time_emb_dim</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="mi">8</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">time_emb_dim</span><span class="p">,</span> <span class="n">dim_out</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span> <span class="k">if</span> <span class="n">exists</span><span class="p">(</span><span class="n">time_emb_dim</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">block1</span> <span class="o">=</span> <span class="n">Block</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">groups</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block2</span> <span class="o">=</span> <span class="n">Block</span><span class="p">(</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">groups</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">res_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">!=</span> <span class="n">dim_out</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">time_emb</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>

        <span class="n">scale_shift</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">)</span> <span class="ow">and</span> <span class="n">exists</span><span class="p">(</span><span class="n">time_emb</span><span class="p">):</span>
            <span class="n">time_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">time_emb</span><span class="p">)</span>
            <span class="n">time_emb</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">time_emb</span><span class="p">,</span> <span class="s1">&#39;b c -&gt; b c 1&#39;</span><span class="p">)</span>
            <span class="n">scale_shift</span> <span class="o">=</span> <span class="n">time_emb</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">scale_shift</span> <span class="o">=</span> <span class="n">scale_shift</span><span class="p">)</span>

        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block2</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">h</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">res_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">LinearAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">heads</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">dim_head</span> <span class="o">=</span> <span class="mi">32</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">dim_head</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">heads</span>
        <span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">dim_head</span> <span class="o">*</span> <span class="n">heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to_qkv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">to_out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">RMSNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">qkv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_qkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="s1">&#39;b (h c) n -&gt; b h c n&#39;</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">heads</span><span class="p">),</span> <span class="n">qkv</span><span class="p">)</span>

        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>        

        <span class="n">context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;b h d n, b h e n -&gt; b h d e&#39;</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;b h d e, b h d n -&gt; b h e n&#39;</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="s1">&#39;b h c n -&gt; b (h c) n&#39;</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">heads</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_out</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">heads</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">dim_head</span> <span class="o">=</span> <span class="mi">32</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">dim_head</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">heads</span>
        <span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">dim_head</span> <span class="o">*</span> <span class="n">heads</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">to_qkv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to_out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">qkv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_qkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="s1">&#39;b (h c) n -&gt; b h c n&#39;</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">heads</span><span class="p">),</span> <span class="n">qkv</span><span class="p">)</span>

        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>

        <span class="n">sim</span> <span class="o">=</span> <span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;b h d i, b h d j -&gt; b h i j&#39;</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
        <span class="n">attn</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;b h i j, b h d j -&gt; b h i d&#39;</span><span class="p">,</span> <span class="n">attn</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="s1">&#39;b h n d -&gt; b (h d) n&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_out</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</code></pre></div>
<p>代码定义了一些用于构建深度学习模型的基础模块。下面是每个函数和类的作用：</p>
<ol>
<li>
<p><code>Residual</code>：残差模块，它将输入x通过一个函数fn处理后，再加上原始的输入x，形成了一个残差连接。</p>
</li>
<li>
<p><code>Upsample</code> 和 <code>Downsample</code>：两个函数分别用于上采样和下采样。上采样是将输入的特征图放大，下采样则是将输入的特征图缩小。</p>
</li>
<li>
<p><code>RMSNorm</code>：归一化层，它使用RMSNorm方法进行归一化。归一化可以帮助模型更好地学习和理解数据。</p>
</li>
<li>
<p><code>PreNorm</code>：预归一化模块，它先对输入进行归一化，然后再通过一个函数进行处理。</p>
</li>
<li>
<p><code>SinusoidalPosEmb</code> 和 <code>RandomOrLearnedSinusoidalPosEmb</code>：两个类用于生成正弦位置嵌入。位置嵌入是用于处理序列数据的一种技术，它可以帮助模型理解序列中的元素的位置关系。</p>
</li>
<li>
<p><code>Block</code>：基础的卷积块，它包含一个卷积层，一个归一化层，和一个激活函数。</p>
</li>
<li>
<p><code>ResnetBlock</code>：ResNet风格的卷积块，它包含两个基础卷积块和一个残差连接。</p>
</li>
<li>
<p><code>LinearAttention</code> 和 <code>Attention</code>：两个类都是用于实现注意力机制的模块。注意力机制是一种让模型在处理数据时能够关注到重要部分的技术。</p>
</li>
</ol>
<h4 id="多维_4">多维<a class="headerlink" href="#多维_4" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">Upsample</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim_out</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;nearest&#39;</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">default</span><span class="p">(</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">dim</span><span class="p">),</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span>

<span class="k">def</span> <span class="nf">Downsample</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim_out</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">Rearrange</span><span class="p">(</span><span class="s1">&#39;b c (h p1) (w p2) -&gt; b (c p1 p2) h w&#39;</span><span class="p">,</span> <span class="n">p1</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">p2</span> <span class="o">=</span> <span class="mi">2</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">default</span><span class="p">(</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">dim</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span>

<span class="k">class</span> <span class="nc">RMSNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">g</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">g</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="c1"># sinusoidal positional embeds</span>

<span class="k">class</span> <span class="nc">SinusoidalPosEmb</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span>
        <span class="n">half_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">half_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">half_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="n">emb</span><span class="p">)</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">emb</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">emb</span><span class="o">.</span><span class="n">sin</span><span class="p">(),</span> <span class="n">emb</span><span class="o">.</span><span class="n">cos</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">emb</span>

<span class="k">class</span> <span class="nc">RandomOrLearnedSinusoidalPosEmb</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; following @crowsonkb &#39;s lead with random (learned optional) sinusoidal pos emb &quot;&quot;&quot;</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; https://github.com/crowsonkb/v-diffusion-jax/blob/master/diffusion/models/danbooru_128.py#L8 &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">is_random</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">divisible_by</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">half_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">half_dim</span><span class="p">),</span> <span class="n">requires_grad</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">is_random</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;b -&gt; b 1&#39;</span><span class="p">)</span>
        <span class="n">freqs</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">rearrange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="s1">&#39;d -&gt; 1 d&#39;</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span>
        <span class="n">fouriered</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">freqs</span><span class="o">.</span><span class="n">sin</span><span class="p">(),</span> <span class="n">freqs</span><span class="o">.</span><span class="n">cos</span><span class="p">()),</span> <span class="n">dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">fouriered</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">fouriered</span><span class="p">),</span> <span class="n">dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fouriered</span>

<span class="c1"># building block modules</span>

<span class="k">class</span> <span class="nc">Block</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="mi">8</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">scale_shift</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">exists</span><span class="p">(</span><span class="n">scale_shift</span><span class="p">):</span>
            <span class="n">scale</span><span class="p">,</span> <span class="n">shift</span> <span class="o">=</span> <span class="n">scale_shift</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="n">scale</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">shift</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">class</span> <span class="nc">ResnetBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">time_emb_dim</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="mi">8</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">time_emb_dim</span><span class="p">,</span> <span class="n">dim_out</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span> <span class="k">if</span> <span class="n">exists</span><span class="p">(</span><span class="n">time_emb_dim</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">block1</span> <span class="o">=</span> <span class="n">Block</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">groups</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block2</span> <span class="o">=</span> <span class="n">Block</span><span class="p">(</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">groups</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">res_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">!=</span> <span class="n">dim_out</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">time_emb</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>

        <span class="n">scale_shift</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">)</span> <span class="ow">and</span> <span class="n">exists</span><span class="p">(</span><span class="n">time_emb</span><span class="p">):</span>
            <span class="n">time_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">time_emb</span><span class="p">)</span>
            <span class="n">time_emb</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">time_emb</span><span class="p">,</span> <span class="s1">&#39;b c -&gt; b c 1 1&#39;</span><span class="p">)</span>
            <span class="n">scale_shift</span> <span class="o">=</span> <span class="n">time_emb</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">scale_shift</span> <span class="o">=</span> <span class="n">scale_shift</span><span class="p">)</span>

        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block2</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">h</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">res_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">LinearAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dim</span><span class="p">,</span>
        <span class="n">heads</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">dim_head</span> <span class="o">=</span> <span class="mi">32</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">dim_head</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">heads</span>
        <span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">dim_head</span> <span class="o">*</span> <span class="n">heads</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">RMSNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to_qkv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">to_out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">RMSNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">qkv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_qkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="s1">&#39;b (h c) x y -&gt; b h c (x y)&#39;</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">heads</span><span class="p">),</span> <span class="n">qkv</span><span class="p">)</span>

        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">q</span> <span class="o">=</span> <span class="n">q</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>

        <span class="n">context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;b h d n, b h e n -&gt; b h d e&#39;</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;b h d e, b h d n -&gt; b h e n&#39;</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="s1">&#39;b h c (x y) -&gt; b (h c) x y&#39;</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">heads</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">h</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">w</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_out</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dim</span><span class="p">,</span>
        <span class="n">heads</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">dim_head</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
        <span class="n">flash</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">heads</span>
        <span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">dim_head</span> <span class="o">*</span> <span class="n">heads</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">RMSNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attend</span> <span class="o">=</span> <span class="n">Attend</span><span class="p">(</span><span class="n">flash</span> <span class="o">=</span> <span class="n">flash</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">to_qkv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to_out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">qkv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_qkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="s1">&#39;b (h c) x y -&gt; b h (x y) c&#39;</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">heads</span><span class="p">),</span> <span class="n">qkv</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attend</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="s1">&#39;b h (x y) d -&gt; b (h d) x y&#39;</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">h</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">w</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_out</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</code></pre></div>
<p>该段代码与一维代码实现的功能大致相同，但因为主要是针对二维数据设计的，因此在部分方法上有着区别：</p>
<ol>
<li>
<p><code>Upsample</code> 和 <code>Downsample</code>：与一维代码段中的函数相比，使用了二维卷积和二维重排列。</p>
</li>
<li>
<p><code>RMSNorm</code>：与一维代码段中的函数相比，增加了一个维度。</p>
</li>
<li>
<p><code>SinusoidalPosEmb</code> 和 <code>RandomOrLearnedSinusoidalPosEmb</code>：这两个类用于生成正弦位置嵌入。位置嵌入是用于处理序列数据的一种技术，它可以帮助模型理解序列中的元素的位置关系。</p>
</li>
<li>
<p><code>Block</code>：与一维代码段中的函数相比，使用了二维卷积。</p>
</li>
<li>
<p><code>ResnetBlock</code>：与一维代码段中的函数相比，使用了二维卷积。</p>
</li>
<li>
<p><code>LinearAttention</code> 和 <code>Attention</code>：与一维代码段中的函数相比，使用了二维卷积，并且在处理数据时考虑了数据的二维结构。</p>
</li>
</ol>
<h3 id="u-net">U-Net<a class="headerlink" href="#u-net" title="Permanent link">&para;</a></h3>
<p>U-Net是一种常用于图像分割的深度学习模型，它的特点是在编码器和解码器之间有很多的跨层连接。在这个模型中，首先通过一系列的下采样层将数据的维度逐渐减小，然后在中间层进行处理，最后通过一系列的上采样层将数据的维度逐渐恢复，同时在每一层都会有残差连接和注意力机制。</p>
<h4 id="一维_5">一维<a class="headerlink" href="#一维_5" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">Unet1D</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dim</span><span class="p">,</span>
        <span class="n">init_dim</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_dim</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dim_mults</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
        <span class="n">channels</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">self_condition</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">resnet_block_groups</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
        <span class="n">learned_variance</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">learned_sinusoidal_cond</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">random_fourier_features</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">learned_sinusoidal_dim</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
        <span class="n">attn_dim_head</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
        <span class="n">attn_heads</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># determine dimensions</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">channels</span> <span class="o">=</span> <span class="n">channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">self_condition</span> <span class="o">=</span> <span class="n">self_condition</span>
        <span class="n">input_channels</span> <span class="o">=</span> <span class="n">channels</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="k">if</span> <span class="n">self_condition</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">init_dim</span> <span class="o">=</span> <span class="n">default</span><span class="p">(</span><span class="n">init_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">init_dim</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>

        <span class="n">dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">init_dim</span><span class="p">,</span> <span class="o">*</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">m</span><span class="p">:</span> <span class="n">dim</span> <span class="o">*</span> <span class="n">m</span><span class="p">,</span> <span class="n">dim_mults</span><span class="p">)]</span>
        <span class="n">in_out</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">dims</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>

        <span class="n">block_klass</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">ResnetBlock</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">resnet_block_groups</span><span class="p">)</span>

        <span class="c1"># time embeddings</span>

        <span class="n">time_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">*</span> <span class="mi">4</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">random_or_learned_sinusoidal_cond</span> <span class="o">=</span> <span class="n">learned_sinusoidal_cond</span> <span class="ow">or</span> <span class="n">random_fourier_features</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_or_learned_sinusoidal_cond</span><span class="p">:</span>
            <span class="n">sinu_pos_emb</span> <span class="o">=</span> <span class="n">RandomOrLearnedSinusoidalPosEmb</span><span class="p">(</span><span class="n">learned_sinusoidal_dim</span><span class="p">,</span> <span class="n">random_fourier_features</span><span class="p">)</span>
            <span class="n">fourier_dim</span> <span class="o">=</span> <span class="n">learned_sinusoidal_dim</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sinu_pos_emb</span> <span class="o">=</span> <span class="n">SinusoidalPosEmb</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
            <span class="n">fourier_dim</span> <span class="o">=</span> <span class="n">dim</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">time_mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">sinu_pos_emb</span><span class="p">,</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">fourier_dim</span><span class="p">,</span> <span class="n">time_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">time_dim</span><span class="p">,</span> <span class="n">time_dim</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># layers</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">downs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ups</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([])</span>
        <span class="n">num_resolutions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_out</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">in_out</span><span class="p">):</span>
            <span class="n">is_last</span> <span class="o">=</span> <span class="n">ind</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="n">num_resolutions</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">downs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
                <span class="n">block_klass</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_in</span><span class="p">,</span> <span class="n">time_emb_dim</span> <span class="o">=</span> <span class="n">time_dim</span><span class="p">),</span>
                <span class="n">block_klass</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_in</span><span class="p">,</span> <span class="n">time_emb_dim</span> <span class="o">=</span> <span class="n">time_dim</span><span class="p">),</span>
                <span class="n">Residual</span><span class="p">(</span><span class="n">PreNorm</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">LinearAttention</span><span class="p">(</span><span class="n">dim_in</span><span class="p">))),</span>
                <span class="n">Downsample</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">is_last</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">]))</span>

        <span class="n">mid_dim</span> <span class="o">=</span> <span class="n">dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mid_block1</span> <span class="o">=</span> <span class="n">block_klass</span><span class="p">(</span><span class="n">mid_dim</span><span class="p">,</span> <span class="n">mid_dim</span><span class="p">,</span> <span class="n">time_emb_dim</span> <span class="o">=</span> <span class="n">time_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mid_attn</span> <span class="o">=</span> <span class="n">Residual</span><span class="p">(</span><span class="n">PreNorm</span><span class="p">(</span><span class="n">mid_dim</span><span class="p">,</span> <span class="n">Attention</span><span class="p">(</span><span class="n">mid_dim</span><span class="p">,</span> <span class="n">dim_head</span> <span class="o">=</span> <span class="n">attn_dim_head</span><span class="p">,</span> <span class="n">heads</span> <span class="o">=</span> <span class="n">attn_heads</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mid_block2</span> <span class="o">=</span> <span class="n">block_klass</span><span class="p">(</span><span class="n">mid_dim</span><span class="p">,</span> <span class="n">mid_dim</span><span class="p">,</span> <span class="n">time_emb_dim</span> <span class="o">=</span> <span class="n">time_dim</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">in_out</span><span class="p">)):</span>
            <span class="n">is_last</span> <span class="o">=</span> <span class="n">ind</span> <span class="o">==</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">in_out</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">ups</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
                <span class="n">block_klass</span><span class="p">(</span><span class="n">dim_out</span> <span class="o">+</span> <span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">,</span> <span class="n">time_emb_dim</span> <span class="o">=</span> <span class="n">time_dim</span><span class="p">),</span>
                <span class="n">block_klass</span><span class="p">(</span><span class="n">dim_out</span> <span class="o">+</span> <span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">,</span> <span class="n">time_emb_dim</span> <span class="o">=</span> <span class="n">time_dim</span><span class="p">),</span>
                <span class="n">Residual</span><span class="p">(</span><span class="n">PreNorm</span><span class="p">(</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">LinearAttention</span><span class="p">(</span><span class="n">dim_out</span><span class="p">))),</span>
                <span class="n">Upsample</span><span class="p">(</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">dim_in</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">is_last</span> <span class="k">else</span>  <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">dim_in</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">]))</span>

        <span class="n">default_out_dim</span> <span class="o">=</span> <span class="n">channels</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">learned_variance</span> <span class="k">else</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_dim</span> <span class="o">=</span> <span class="n">default</span><span class="p">(</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">default_out_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">final_res_block</span> <span class="o">=</span> <span class="n">block_klass</span><span class="p">(</span><span class="n">dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">time_emb_dim</span> <span class="o">=</span> <span class="n">time_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">x_self_cond</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_condition</span><span class="p">:</span>
            <span class="n">x_self_cond</span> <span class="o">=</span> <span class="n">default</span><span class="p">(</span><span class="n">x_self_cond</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x_self_cond</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

        <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_mlp</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>

        <span class="n">h</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">block1</span><span class="p">,</span> <span class="n">block2</span><span class="p">,</span> <span class="n">attn</span><span class="p">,</span> <span class="n">downsample</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">downs</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">block1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
            <span class="n">h</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

            <span class="n">x</span> <span class="o">=</span> <span class="n">block2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">attn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">h</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

            <span class="n">x</span> <span class="o">=</span> <span class="n">downsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mid_block1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mid_attn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mid_block2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">block1</span><span class="p">,</span> <span class="n">block2</span><span class="p">,</span> <span class="n">attn</span><span class="p">,</span> <span class="n">upsample</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ups</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="o">.</span><span class="n">pop</span><span class="p">()),</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">block1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="o">.</span><span class="n">pop</span><span class="p">()),</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">block2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">attn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

            <span class="n">x</span> <span class="o">=</span> <span class="n">upsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">r</span><span class="p">),</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
<p>上述代码构建了一个一维的U-Net模型，主要用于处理一维序列数据，如音频或时间序列数据。因此，它的输入数据通常是形状为[batch_size, channels, length]的三维张量。在U-Net1D模型中，卷积、上采样和下采样等操作都是一维的。</p>
<p>在<code>Unet1D</code>的<code>forward</code>函数中，首先检查是否设置了自我条件模式，如果设置了，那么会将输入数据和自我条件数据进行拼接。然后通过初始卷积层进行处理，接着将处理后的数据通过一系列的下采样层、中间层和上采样层进行处理，最后通过最终的残差块和卷积层得到输出。在这个过程中，还会使用时间嵌入层对输入的时间进行处理，并将处理后的时间嵌入作为额外的输入传递给各个卷积块和残差块。</p>
<h4 id="多维_5">多维<a class="headerlink" href="#多维_5" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">Unet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dim</span><span class="p">,</span>
        <span class="n">init_dim</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">out_dim</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dim_mults</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
        <span class="n">channels</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">self_condition</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">resnet_block_groups</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
        <span class="n">learned_variance</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">learned_sinusoidal_cond</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">random_fourier_features</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">learned_sinusoidal_dim</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
        <span class="n">attn_dim_head</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
        <span class="n">attn_heads</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">full_attn</span> <span class="o">=</span> <span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span>
        <span class="n">flash_attn</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># determine dimensions</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">channels</span> <span class="o">=</span> <span class="n">channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">self_condition</span> <span class="o">=</span> <span class="n">self_condition</span>
        <span class="n">input_channels</span> <span class="o">=</span> <span class="n">channels</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="k">if</span> <span class="n">self_condition</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">init_dim</span> <span class="o">=</span> <span class="n">default</span><span class="p">(</span><span class="n">init_dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">init_dim</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>

        <span class="n">dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">init_dim</span><span class="p">,</span> <span class="o">*</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">m</span><span class="p">:</span> <span class="n">dim</span> <span class="o">*</span> <span class="n">m</span><span class="p">,</span> <span class="n">dim_mults</span><span class="p">)]</span>
        <span class="n">in_out</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">dims</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>

        <span class="n">block_klass</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">ResnetBlock</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">resnet_block_groups</span><span class="p">)</span>

        <span class="c1"># time embeddings</span>

        <span class="n">time_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">*</span> <span class="mi">4</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">random_or_learned_sinusoidal_cond</span> <span class="o">=</span> <span class="n">learned_sinusoidal_cond</span> <span class="ow">or</span> <span class="n">random_fourier_features</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_or_learned_sinusoidal_cond</span><span class="p">:</span>
            <span class="n">sinu_pos_emb</span> <span class="o">=</span> <span class="n">RandomOrLearnedSinusoidalPosEmb</span><span class="p">(</span><span class="n">learned_sinusoidal_dim</span><span class="p">,</span> <span class="n">random_fourier_features</span><span class="p">)</span>
            <span class="n">fourier_dim</span> <span class="o">=</span> <span class="n">learned_sinusoidal_dim</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sinu_pos_emb</span> <span class="o">=</span> <span class="n">SinusoidalPosEmb</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
            <span class="n">fourier_dim</span> <span class="o">=</span> <span class="n">dim</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">time_mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">sinu_pos_emb</span><span class="p">,</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">fourier_dim</span><span class="p">,</span> <span class="n">time_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">time_dim</span><span class="p">,</span> <span class="n">time_dim</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># attention</span>

        <span class="n">num_stages</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dim_mults</span><span class="p">)</span>
        <span class="n">full_attn</span>  <span class="o">=</span> <span class="n">cast_tuple</span><span class="p">(</span><span class="n">full_attn</span><span class="p">,</span> <span class="n">num_stages</span><span class="p">)</span>
        <span class="n">attn_heads</span> <span class="o">=</span> <span class="n">cast_tuple</span><span class="p">(</span><span class="n">attn_heads</span><span class="p">,</span> <span class="n">num_stages</span><span class="p">)</span>
        <span class="n">attn_dim_head</span> <span class="o">=</span> <span class="n">cast_tuple</span><span class="p">(</span><span class="n">attn_dim_head</span><span class="p">,</span> <span class="n">num_stages</span><span class="p">)</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">full_attn</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">dim_mults</span><span class="p">)</span>

        <span class="n">FullAttention</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">Attention</span><span class="p">,</span> <span class="n">flash</span> <span class="o">=</span> <span class="n">flash_attn</span><span class="p">)</span>

        <span class="c1"># layers</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">downs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ups</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([])</span>
        <span class="n">num_resolutions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_out</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="p">((</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">),</span> <span class="n">layer_full_attn</span><span class="p">,</span> <span class="n">layer_attn_heads</span><span class="p">,</span> <span class="n">layer_attn_dim_head</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">in_out</span><span class="p">,</span> <span class="n">full_attn</span><span class="p">,</span> <span class="n">attn_heads</span><span class="p">,</span> <span class="n">attn_dim_head</span><span class="p">)):</span>
            <span class="n">is_last</span> <span class="o">=</span> <span class="n">ind</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="n">num_resolutions</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">attn_klass</span> <span class="o">=</span> <span class="n">FullAttention</span> <span class="k">if</span> <span class="n">layer_full_attn</span> <span class="k">else</span> <span class="n">LinearAttention</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">downs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
                <span class="n">block_klass</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_in</span><span class="p">,</span> <span class="n">time_emb_dim</span> <span class="o">=</span> <span class="n">time_dim</span><span class="p">),</span>
                <span class="n">block_klass</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_in</span><span class="p">,</span> <span class="n">time_emb_dim</span> <span class="o">=</span> <span class="n">time_dim</span><span class="p">),</span>
                <span class="n">attn_klass</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_head</span> <span class="o">=</span> <span class="n">layer_attn_dim_head</span><span class="p">,</span> <span class="n">heads</span> <span class="o">=</span> <span class="n">layer_attn_heads</span><span class="p">),</span>
                <span class="n">Downsample</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">is_last</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">]))</span>

        <span class="n">mid_dim</span> <span class="o">=</span> <span class="n">dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mid_block1</span> <span class="o">=</span> <span class="n">block_klass</span><span class="p">(</span><span class="n">mid_dim</span><span class="p">,</span> <span class="n">mid_dim</span><span class="p">,</span> <span class="n">time_emb_dim</span> <span class="o">=</span> <span class="n">time_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mid_attn</span> <span class="o">=</span> <span class="n">FullAttention</span><span class="p">(</span><span class="n">mid_dim</span><span class="p">,</span> <span class="n">heads</span> <span class="o">=</span> <span class="n">attn_heads</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dim_head</span> <span class="o">=</span> <span class="n">attn_dim_head</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mid_block2</span> <span class="o">=</span> <span class="n">block_klass</span><span class="p">(</span><span class="n">mid_dim</span><span class="p">,</span> <span class="n">mid_dim</span><span class="p">,</span> <span class="n">time_emb_dim</span> <span class="o">=</span> <span class="n">time_dim</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="p">((</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">),</span> <span class="n">layer_full_attn</span><span class="p">,</span> <span class="n">layer_attn_heads</span><span class="p">,</span> <span class="n">layer_attn_dim_head</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="nb">map</span><span class="p">(</span><span class="nb">reversed</span><span class="p">,</span> <span class="p">(</span><span class="n">in_out</span><span class="p">,</span> <span class="n">full_attn</span><span class="p">,</span> <span class="n">attn_heads</span><span class="p">,</span> <span class="n">attn_dim_head</span><span class="p">)))):</span>
            <span class="n">is_last</span> <span class="o">=</span> <span class="n">ind</span> <span class="o">==</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">in_out</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">attn_klass</span> <span class="o">=</span> <span class="n">FullAttention</span> <span class="k">if</span> <span class="n">layer_full_attn</span> <span class="k">else</span> <span class="n">LinearAttention</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">ups</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
                <span class="n">block_klass</span><span class="p">(</span><span class="n">dim_out</span> <span class="o">+</span> <span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">,</span> <span class="n">time_emb_dim</span> <span class="o">=</span> <span class="n">time_dim</span><span class="p">),</span>
                <span class="n">block_klass</span><span class="p">(</span><span class="n">dim_out</span> <span class="o">+</span> <span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_out</span><span class="p">,</span> <span class="n">time_emb_dim</span> <span class="o">=</span> <span class="n">time_dim</span><span class="p">),</span>
                <span class="n">attn_klass</span><span class="p">(</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">dim_head</span> <span class="o">=</span> <span class="n">layer_attn_dim_head</span><span class="p">,</span> <span class="n">heads</span> <span class="o">=</span> <span class="n">layer_attn_heads</span><span class="p">),</span>
                <span class="n">Upsample</span><span class="p">(</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">dim_in</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">is_last</span> <span class="k">else</span>  <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">dim_out</span><span class="p">,</span> <span class="n">dim_in</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
            <span class="p">]))</span>

        <span class="n">default_out_dim</span> <span class="o">=</span> <span class="n">channels</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">learned_variance</span> <span class="k">else</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_dim</span> <span class="o">=</span> <span class="n">default</span><span class="p">(</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">default_out_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">final_res_block</span> <span class="o">=</span> <span class="n">block_klass</span><span class="p">(</span><span class="n">dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">time_emb_dim</span> <span class="o">=</span> <span class="n">time_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">downsample_factor</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">downs</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">x_self_cond</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">([</span><span class="n">divisible_by</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample_factor</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]]),</span> <span class="sa">f</span><span class="s1">&#39;your input dimensions </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span><span class="si">}</span><span class="s1"> need to be divisible by </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">downsample_factor</span><span class="si">}</span><span class="s1">, given the unet&#39;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_condition</span><span class="p">:</span>
            <span class="n">x_self_cond</span> <span class="o">=</span> <span class="n">default</span><span class="p">(</span><span class="n">x_self_cond</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x_self_cond</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

        <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_mlp</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>

        <span class="n">h</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">block1</span><span class="p">,</span> <span class="n">block2</span><span class="p">,</span> <span class="n">attn</span><span class="p">,</span> <span class="n">downsample</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">downs</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">block1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
            <span class="n">h</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

            <span class="n">x</span> <span class="o">=</span> <span class="n">block2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">attn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">x</span>
            <span class="n">h</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

            <span class="n">x</span> <span class="o">=</span> <span class="n">downsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mid_block1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mid_attn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mid_block2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">block1</span><span class="p">,</span> <span class="n">block2</span><span class="p">,</span> <span class="n">attn</span><span class="p">,</span> <span class="n">upsample</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ups</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="o">.</span><span class="n">pop</span><span class="p">()),</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">block1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="o">.</span><span class="n">pop</span><span class="p">()),</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">block2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">attn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">x</span>

            <span class="n">x</span> <span class="o">=</span> <span class="n">upsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">r</span><span class="p">),</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_res_block</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
<p>与修改后的 U-Net1D 相比，原始的U-Net模型是用于处理二维图像数据的，因此它的输入数据通常是形状为[batch_size, channels, height, width]的四维张量。在U-Net模型中，卷积、上采样和下采样等操作都是二维的。</p>
<h4 id="对比">对比<a class="headerlink" href="#对比" title="Permanent link">&para;</a></h4>
<p>由于上述 U-Net 模型针对处理的数据维度有区别，导致其使用的操作也存在不同。其主要区别如下：</p>
<ol>
<li>
<p>数据维度：Unet类处理的是二维数据，因此它使用的是二维卷积（nn.Conv2d），二维上采样和二维下采样。而Unet1D类处理的是一维数据，因此它使用的是一维卷积（nn.Conv1d），一维上采样和一维下采样。</p>
</li>
<li>
<p>模型结构：Unet和Unet1D类的模型结构基本相同，都包含了下采样（downsampling）、上采样（upsampling）和跳跃连接（skip connection）。他们都使用了残差块（ResnetBlock）和注意力机制（Attention）。但是在实现细节上，由于处理的数据维度不同，所以他们使用的操作也不同。</p>
</li>
<li>
<p>注意力机制：在Unet类中，使用了全注意力（FullAttention）和线性注意力（LinearAttention）。而在Unet1D类中，只使用了线性注意力（LinearAttention）。</p>
</li>
<li>
<p>时间嵌入：Unet和Unet1D类都使用了时间嵌入（time embeddings），这是一种处理序列数据中的位置信息的方法。他们都使用了正弦位置嵌入（SinusoidalPosEmb）或者随机或学习的正弦位置嵌入（RandomOrLearnedSinusoidalPosEmb）。</p>
</li>
<li>
<p>输入数据的形状：Unet类的输入数据的形状通常是[batch_size, channels, height, width]，而Unet1D类的输入数据的形状通常是[batch_size, channels, length]。</p>
</li>
<li>
<p>自我条件（self-condition）：Unet和Unet1D类都支持自我条件（self-condition），这是一种让模型能够处理自我监督学习任务的方法。如果启用了自我条件，那么模型的输入数据会包含两部分：一部分是原始的输入数据，另一部分是自我条件的数据。</p>
</li>
<li>
<p>输出数据的形状：Unet类的输出数据的形状是[batch_size, out_dim, height, width]，而Unet1D类的输出数据的形状是[batch_size, out_dim, length]。</p>
</li>
</ol>
<p>需要注意的是，U-Net1D模型还包含了一些特殊的设计，如使用了位置嵌入（Position Embedding）来处理序列数据中的位置信息，使用了注意力机制（Attention）来让模型能够关注到序列中的重要部分，以及使用了残差连接（Residual Connection）和归一化（Normalization）等技术来提升模型的性能。</p>

  <hr>
<div class="md-source-file">
  <small>
    
      Last update:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2023-07-22</span>
      
        <br>
        Created:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2023-07-22</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            Back to top
          </a>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../../../Multimodal/Paper%20Reading/A%20Review%20on%20Methods%20and%20Applications%20in%20Multimodal%20Deep%20Learning/" class="md-footer__link md-footer__link--prev" aria-label="Previous: A Review on Methods and Applications in Multimodal Deep Learning" rel="prev">
            <div class="md-footer__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <div class="md-ellipsis">
                <span class="md-footer__direction">
                  Previous
                </span>
                A Review on Methods and Applications in Multimodal Deep Learning
              </div>
            </div>
          </a>
        
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2021 - 2023 W
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
      
      
    
    <a href="https://twitter.com/squidfunk" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.path", "search.share", "navigation.instant", "navigation.tabs", "navigation.expand", "navigation.top", "navigation.footer", "toc.follow"], "search": "../../../../assets/javascripts/workers/search.e5c33ebb.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.51d95adb.min.js"></script>
      
    
  </body>
</html>